{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "FNO3d (Spatio-temporal Fourier Neural Operator) Training and Evaluation Script\n",
    "\n",
    "This script implements the FNO3d model for flood inundation forecasting,\n",
    "including data loading (with multiple resolution and chunking strategies),\n",
    "model definition (FNO3d, SpectralConv3d), custom loss functions, and a\n",
    "full training/evaluation loop with hyperparameter grid search.\n",
    "\n",
    "This code is refactored from a Jupyter Notebook, standardizing it for\n",
    "command-line execution and public release.\n",
    "\n",
    "Key Features:\n",
    "- FNO3d model architecture with 3D spectral convolutions.\n",
    "- Dynamic 3D positional encoding with caching.\n",
    "- Multiple Dataset classes for different loading strategies:\n",
    "    - Flood3DMultiEventDataset: Loads all training events from a directory.\n",
    "    - Flood3DTestDataset: Loads a full test event into RAM (for 100m data).\n",
    "    - Flood3DChunkedTestDataset: Loads a test event in chunks (for 30m data).\n",
    "- Hyperparameter grid search via command-line arguments.\n",
    "- Robust memory management with explicit gc.collect() and torch.cuda.empty_cache().\n",
    "- Logging for training progress and evaluation results.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import h5py\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import glob\n",
    "import math\n",
    "import gc\n",
    "import psutil\n",
    "import logging\n",
    "import argparse  # Import argparse for command-line arguments\n",
    "from typing import List, Tuple, Optional, Dict, Any\n",
    "\n",
    "# PyTorch Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Scikit-learn Imports\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# =========================\n",
    "# 1. Memory Management Utilities\n",
    "# =========================\n",
    "\n",
    "def print_memory_usage(logger: logging.Logger):\n",
    "    \"\"\"\n",
    "    Logs the current CPU and GPU memory usage.\n",
    "    \"\"\"\n",
    "    # CPU Memory\n",
    "    process = psutil.Process(os.getpid())\n",
    "    cpu_memory = process.memory_info().rss / (1024 * 1024)  # MB\n",
    "    logger.info(f\"CPU Memory Usage: {cpu_memory:.2f} MB\")\n",
    "    \n",
    "    # GPU Memory (if available)\n",
    "    if torch.cuda.is_available():\n",
    "        for i in range(torch.cuda.device_count()):\n",
    "            reserved = torch.cuda.memory_reserved(i) / (1024 * 1024)  # MB\n",
    "            allocated = torch.cuda.memory_allocated(i) / (1024 * 1024)  # MB\n",
    "            logger.info(f\"GPU:{i} Reserved Memory: {reserved:.2f} MB, Allocated Memory: {allocated:.2f} MB\")\n",
    "\n",
    "def clean_memory():\n",
    "    \"\"\"\n",
    "    Performs garbage collection and empties the CUDA cache.\n",
    "    \"\"\"\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "# =========================\n",
    "# 2. Logging and Seeding Utilities\n",
    "# =========================\n",
    "\n",
    "def setup_logging() -> logging.Logger:\n",
    "    \"\"\"\n",
    "    Configures a global logger.\n",
    "    \"\"\"\n",
    "    logger = logging.getLogger()\n",
    "    logger.setLevel(logging.INFO)\n",
    "    if logger.hasHandlers():\n",
    "        logger.handlers.clear()\n",
    "    \n",
    "    ch = logging.StreamHandler()\n",
    "    ch.setLevel(logging.INFO)\n",
    "    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "    ch.setFormatter(formatter)\n",
    "    logger.addHandler(ch)\n",
    "    return logger\n",
    "\n",
    "# Initialize global logger\n",
    "logger = setup_logging()\n",
    "\n",
    "def set_seed(seed: int = 42, deterministic: bool = True):\n",
    "    \"\"\"\n",
    "    Sets random seeds for reproducibility.\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    if deterministic:\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def seed_worker(worker_id: int):\n",
    "    \"\"\"\n",
    "    Sets the random seed for a DataLoader worker.\n",
    "    \"\"\"\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "# =========================\n",
    "# 3. Custom Loss Functions\n",
    "# =========================\n",
    "\n",
    "class DynamicWeightedMSELoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Dynamic Weighted MSE Loss.\n",
    "    \n",
    "    This loss function applies different weights to the MSE loss based on\n",
    "    the magnitude (percentiles) of the target (ground truth) values.\n",
    "    It uses a caching mechanism to update the thresholds periodically.\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 percentile_thresholds: List[float] = [50, 75, 90], \n",
    "                 weights_multipliers: List[float] = [1.0, 2.0, 5.0, 10.0], \n",
    "                 eps: float = 1e-8,\n",
    "                 update_freq: int = 10):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            percentile_thresholds: List of percentiles to define water depth bins.\n",
    "            weights_multipliers: List of weights for each bin. Length must be\n",
    "                                 len(percentile_thresholds) + 1.\n",
    "            eps: Small value to prevent division by zero in masked loss.\n",
    "            update_freq: How often (in batches) to update the thresholds.\n",
    "        \"\"\"\n",
    "        super(DynamicWeightedMSELoss, self).__init__()\n",
    "        self.percentile_thresholds = percentile_thresholds\n",
    "        self.weights_multipliers = weights_multipliers\n",
    "        self.eps = eps\n",
    "        self.update_freq = update_freq\n",
    "        \n",
    "        self.thresholds_cache = None\n",
    "        self.call_count = 0\n",
    "        \n",
    "        if len(weights_multipliers) != len(percentile_thresholds) + 1:\n",
    "            raise ValueError(\"Length of weights_multipliers must be len(percentile_thresholds) + 1\")\n",
    "    \n",
    "    def update_thresholds(self, targets: torch.Tensor, mask: Optional[torch.Tensor] = None) -> Optional[List[torch.Tensor]]:\n",
    "        \"\"\"\n",
    "        Updates the percentile thresholds based on the current batch.\n",
    "        \"\"\"\n",
    "        if mask is not None:\n",
    "            valid_targets = targets[mask > 0.5]\n",
    "        else:\n",
    "            valid_targets = targets.reshape(-1)\n",
    "        \n",
    "        if valid_targets.numel() == 0:\n",
    "            return None\n",
    "        \n",
    "        thresholds = []\n",
    "        for p in self.percentile_thresholds:\n",
    "            threshold = torch.quantile(valid_targets, p / 100.0)\n",
    "            thresholds.append(threshold)\n",
    "        \n",
    "        return thresholds\n",
    "    \n",
    "    def forward(self, \n",
    "                outputs: torch.Tensor, \n",
    "                targets: torch.Tensor, \n",
    "                mask: Optional[torch.Tensor] = None) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Calculates the dynamic weighted MSE loss.\n",
    "        \n",
    "        Args:\n",
    "            outputs: Model predictions (B, 1, H, W)\n",
    "            targets: Ground truth labels (B, 1, H, W)\n",
    "            mask: Optional mask for valid areas (B, 1, H, W)\n",
    "            \n",
    "        Returns:\n",
    "            Weighted MSE loss tensor (B, 1, H, W)\n",
    "        \"\"\"\n",
    "        mse = (outputs - targets) ** 2\n",
    "        \n",
    "        self.call_count += 1\n",
    "        if self.thresholds_cache is None or self.call_count % self.update_freq == 0:\n",
    "            self.thresholds_cache = self.update_thresholds(targets, mask)\n",
    "            \n",
    "        if self.thresholds_cache is None:\n",
    "            return mse\n",
    "        \n",
    "        thresholds = self.thresholds_cache\n",
    "        \n",
    "        # Start with the base weight\n",
    "        weights = torch.ones_like(targets) * self.weights_multipliers[0]\n",
    "        \n",
    "        # Apply weights for different percentile ranges\n",
    "        for i in range(len(thresholds)):\n",
    "            if i == 0:\n",
    "                # First interval: (0, threshold_0]\n",
    "                condition = (targets > 0) & (targets <= thresholds[i])\n",
    "            else:\n",
    "                # Mid intervals: (threshold_i-1, threshold_i]\n",
    "                condition = (targets > thresholds[i-1]) & (targets <= thresholds[i])\n",
    "                \n",
    "            weights = torch.where(condition, \n",
    "                                 self.weights_multipliers[i] * torch.ones_like(targets),\n",
    "                                 weights)\n",
    "        \n",
    "        # Last interval: (threshold_last, infinity)\n",
    "        weights = torch.where(targets > thresholds[-1],\n",
    "                             self.weights_multipliers[-1] * torch.ones_like(targets),\n",
    "                             weights)\n",
    "        \n",
    "        weighted_mse = mse * weights\n",
    "        \n",
    "        return weighted_mse  # Return per-pixel loss (B, 1, H, W)\n",
    "\n",
    "class StandardMSELoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Wrapper for standard nn.MSELoss to match the interface of\n",
    "    DynamicWeightedMSELoss, accepting a mask argument.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(StandardMSELoss, self).__init__()\n",
    "        # reduction='none' keeps the per-pixel loss\n",
    "        self.mse = nn.MSELoss(reduction='none')\n",
    "    \n",
    "    def forward(self, \n",
    "                outputs: torch.Tensor, \n",
    "                targets: torch.Tensor, \n",
    "                mask: Optional[torch.Tensor] = None) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Calculates the standard MSE loss.\n",
    "        \n",
    "        Args:\n",
    "            outputs: Model predictions (B, 1, H, W)\n",
    "            targets: Ground truth labels (B, 1, H, W)\n",
    "            mask: Optional mask (ignored by this loss, but accepted\n",
    "                  for compatibility).\n",
    "            \n",
    "        Returns:\n",
    "            MSE loss tensor (B, 1, H, W)\n",
    "        \"\"\"\n",
    "        return self.mse(outputs, targets)\n",
    "\n",
    "# =========================\n",
    "# 4. Dataset Classes\n",
    "# =========================\n",
    "\n",
    "class Flood3DMultiEventDataset(Dataset):\n",
    "    \"\"\"\n",
    "    3D Spatio-temporal Dataset for multiple flood events.\n",
    "    Loads all samples from all H5 files in a directory into RAM.\n",
    "    \n",
    "    Expected file format in data_dir:\n",
    "    - *_X.h5 or *_X_norm.h5 (Driver data)\n",
    "    - *_Y.h5 or *_Y_norm.h5 (Label data)\n",
    "    \n",
    "    H5 structure:\n",
    "    - driver_key: (num_samples, T, H, W, C_in)\n",
    "    - label_key: (num_samples, H, W, C_out)\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 data_dir: str, \n",
    "                 time_steps: int = 11, \n",
    "                 transform: Optional[Any] = None, \n",
    "                 driver_key: str = 'X_data', \n",
    "                 label_key: str = 'Y_data'):\n",
    "        \n",
    "        self.time_steps = time_steps\n",
    "        self.transform = transform\n",
    "        self.driver_key = driver_key\n",
    "        self.label_key = label_key\n",
    "        \n",
    "        driver_files = sorted(glob.glob(os.path.join(data_dir, \"*_X*.h5\")))\n",
    "        label_files = sorted(glob.glob(os.path.join(data_dir, \"*_Y*.h5\")))\n",
    "        \n",
    "        if len(driver_files) != len(label_files):\n",
    "            raise ValueError(f\"Driver file count ({len(driver_files)}) != Label file count ({len(label_files)}) in {data_dir}\")\n",
    "        \n",
    "        if len(driver_files) == 0:\n",
    "            raise FileNotFoundError(f\"No data files found in {data_dir}\")\n",
    "        \n",
    "        self.input_tensors = []\n",
    "        self.label_tensors = []\n",
    "        self.mask_tensors = []\n",
    "        \n",
    "        for driver_file, label_file in zip(driver_files, label_files):\n",
    "            event_name = os.path.basename(driver_file).replace(\"_X.h5\", \"\").replace(\"_X_norm.h5\", \"\")\n",
    "            logger.info(f\"Loading training event: {event_name}\")\n",
    "            \n",
    "            with h5py.File(driver_file, 'r') as hf:\n",
    "                driver_data = hf[self.driver_key][:]\n",
    "            \n",
    "            with h5py.File(label_file, 'r') as hf:\n",
    "                label_data = hf[self.label_key][:]\n",
    "            \n",
    "            if driver_data.shape[1] != time_steps:\n",
    "                logger.warning(f\"Event {event_name} has {driver_data.shape[1]} time steps, expected {time_steps}. Skipping.\")\n",
    "                continue\n",
    "            \n",
    "            num_samples = driver_data.shape[0]\n",
    "            \n",
    "            for i in range(num_samples):\n",
    "                driver_sequence = driver_data[i].astype(np.float32)  # (T, H, W, C_in)\n",
    "                \n",
    "                # Mask is 5th channel (index 4) of the last time step\n",
    "                mask = driver_sequence[-1, ..., 4]  # (H, W)\n",
    "                mask = np.expand_dims(mask, axis=0)  # (1, H, W)\n",
    "                \n",
    "                # Transpose input to (T, C_in, H, W)\n",
    "                input_data = np.transpose(driver_sequence, (0, 3, 1, 2))\n",
    "                \n",
    "                # Prepare label (1, H, W)\n",
    "                label = label_data[i].squeeze(-1) if label_data[i].shape[-1] == 1 else label_data[i]\n",
    "                label = np.expand_dims(label, axis=0)\n",
    "                \n",
    "                if self.transform:\n",
    "                    input_data, label, mask = self.transform(input_data, label, mask)\n",
    "                \n",
    "                self.input_tensors.append(torch.from_numpy(input_data).float())\n",
    "                self.label_tensors.append(torch.from_numpy(label).float())\n",
    "                self.mask_tensors.append(torch.from_numpy(mask).float())\n",
    "            \n",
    "            del driver_data, label_data\n",
    "            gc.collect()\n",
    "        \n",
    "        self.num_samples = len(self.input_tensors)\n",
    "        logger.info(f\"Loaded {self.num_samples} training samples in total.\")\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return self.num_samples\n",
    "    \n",
    "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        return (\n",
    "            self.input_tensors[idx],    # (T, C_in, H, W)\n",
    "            self.label_tensors[idx],    # (1, H, W)\n",
    "            self.mask_tensors[idx]      # (1, H, W)\n",
    "        )\n",
    "\n",
    "class Flood3DTestDataset(Dataset):\n",
    "    \"\"\"\n",
    "    3D Spatio-temporal Test Dataset.\n",
    "    Loads the *entire* test event into RAM upon initialization.\n",
    "    Suitable for smaller datasets (e.g., 100m resolution).\n",
    "    \n",
    "    H5 structure:\n",
    "    - driver_key: (num_samples, T, H, W, C_in)\n",
    "    - label_key: (num_samples, H, W, C_out)\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 driver_path: str, \n",
    "                 label_path: str, \n",
    "                 driver_key: str = 'data', \n",
    "                 label_key: str = 'data',\n",
    "                 time_steps: int = 11):\n",
    "        \n",
    "        with h5py.File(driver_path, 'r') as hf:\n",
    "            self.driver_data = hf[driver_key][:]\n",
    "            \n",
    "        with h5py.File(label_path, 'r') as hf:\n",
    "            self.label_data = hf[label_key][:]\n",
    "\n",
    "        # Handle potential single-sample files\n",
    "        if self.driver_data.ndim == 5 and self.driver_data.shape[0] == 1:\n",
    "            self.driver_data = np.expand_dims(self.driver_data[0], axis=0)\n",
    "        if self.label_data.ndim == 4 and self.label_data.shape[0] == 1:\n",
    "            self.label_data = np.expand_dims(self.label_data[0], axis=0)\n",
    "\n",
    "        assert self.driver_data.shape[0] == self.label_data.shape[0], \"Sample count mismatch\"\n",
    "        assert self.driver_data.shape[1] == time_steps, f\"Time steps must be {time_steps}\"\n",
    "\n",
    "        self.num_samples = self.driver_data.shape[0]\n",
    "        self.time_steps = time_steps\n",
    "\n",
    "        # Pre-process masks (N, 1, H, W)\n",
    "        self.masks = self.driver_data[:, -1, ..., 4]  # (N, H, W)\n",
    "        self.masks = np.expand_dims(self.masks, axis=1).astype(np.float32)\n",
    "\n",
    "        # Pre-process inputs (N, T, C_in, H, W)\n",
    "        self.inputs = np.transpose(self.driver_data, (0, 1, 4, 2, 3)).astype(np.float32)\n",
    "        \n",
    "        self.label_data = self.label_data.astype(np.float32)\n",
    "\n",
    "        del self.driver_data\n",
    "        gc.collect()\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.num_samples\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        x = self.inputs[idx]  # (T, C_in, H, W)\n",
    "        \n",
    "        y = self.label_data[idx].squeeze(-1) if self.label_data[idx].ndim == 3 else self.label_data[idx]\n",
    "        y = np.expand_dims(y, axis=0)  # (1, H, W)\n",
    "        \n",
    "        m = self.masks[idx]  # (1, H, W)\n",
    "\n",
    "        return (\n",
    "            torch.from_numpy(x).float(),\n",
    "            torch.from_numpy(y).float(),\n",
    "            torch.from_numpy(m).float()\n",
    "        )\n",
    "\n",
    "class Flood3DChunkedTestDataset(Dataset):\n",
    "    \"\"\"\n",
    "    3D Spatio-temporal Test Dataset with Chunked Loading.\n",
    "    Loads data in chunks, suitable for very large high-resolution (30m) data\n",
    "    that does not fit into RAM.\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 driver_path: str, \n",
    "                 label_path: str, \n",
    "                 driver_key: str = 'data', \n",
    "                 label_key: str = 'data',\n",
    "                 time_steps: int = 11, \n",
    "                 chunk_size: int = 4):\n",
    "        \n",
    "        if not os.path.isfile(driver_path):\n",
    "            raise FileNotFoundError(f\"Driver file not found: {driver_path}\")\n",
    "        if not os.path.isfile(label_path):\n",
    "            raise FileNotFoundError(f\"Label file not found: {label_path}\")\n",
    "\n",
    "        self.driver_path = driver_path\n",
    "        self.label_path = label_path\n",
    "        self.driver_key = driver_key\n",
    "        self.label_key = label_key\n",
    "        self.time_steps = time_steps\n",
    "        self.chunk_size = chunk_size\n",
    "        \n",
    "        with h5py.File(driver_path, 'r') as hf:\n",
    "            data_shape = hf[driver_key].shape\n",
    "            if len(data_shape) == 5 and data_shape[0] == 1:\n",
    "                self.num_samples = 1\n",
    "            else:\n",
    "                self.num_samples = data_shape[0]\n",
    "        \n",
    "        self.current_chunk_idx = -1\n",
    "        self.current_chunk_data = None\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.num_samples\n",
    "    \n",
    "    def load_chunk(self, chunk_idx: int):\n",
    "        \"\"\"Loads a specific chunk of data into memory.\"\"\"\n",
    "        start_idx = chunk_idx * self.chunk_size\n",
    "        end_idx = min(start_idx + self.chunk_size, self.num_samples)\n",
    "        \n",
    "        logger.info(f\"Loading data chunk {chunk_idx}, samples: {start_idx} to {end_idx-1}\")\n",
    "        \n",
    "        if self.current_chunk_data is not None:\n",
    "            del self.current_chunk_data\n",
    "            self.current_chunk_data = None\n",
    "            clean_memory()\n",
    "        \n",
    "        with h5py.File(self.driver_path, 'r') as hf:\n",
    "            if self.num_samples == 1 and len(hf[self.driver_key].shape) == 5 and hf[self.driver_key].shape[0] == 1:\n",
    "                driver_data = np.expand_dims(hf[self.driver_key][0], axis=0)\n",
    "            else:\n",
    "                driver_data = hf[self.driver_key][start_idx:end_idx]\n",
    "        \n",
    "        with h5py.File(self.label_path, 'r') as hf:\n",
    "            if self.num_samples == 1 and len(hf[self.label_key].shape) == 4 and hf[self.label_key].shape[0] == 1:\n",
    "                label_data = np.expand_dims(hf[self.label_key][0], axis=0)\n",
    "            else:\n",
    "                label_data = hf[self.label_key][start_idx:end_idx]\n",
    "        \n",
    "        driver_data = driver_data.astype(np.float32)\n",
    "        label_data = label_data.astype(np.float32)\n",
    "        \n",
    "        input_tensors, label_tensors, mask_tensors = [], [], []\n",
    "        \n",
    "        for i in range(driver_data.shape[0]):\n",
    "            mask = driver_data[i, -1, ..., 4]  # (H, W)\n",
    "            mask = np.expand_dims(mask, axis=0)  # (1, H, W)\n",
    "            \n",
    "            input_data = np.transpose(driver_data[i], (0, 3, 1, 2))  # (T, C_in, H, W)\n",
    "            \n",
    "            label_sample = label_data[i].squeeze(-1) if label_data[i].ndim == 3 else label_data[i]\n",
    "            label_sample = np.expand_dims(label_sample, 0)  # (1, H, W)\n",
    "            \n",
    "            input_tensors.append(torch.from_numpy(input_data).float())\n",
    "            label_tensors.append(torch.from_numpy(label_sample).float())\n",
    "            mask_tensors.append(torch.from_numpy(mask).float())\n",
    "        \n",
    "        del driver_data, label_data\n",
    "        gc.collect()\n",
    "        \n",
    "        self.current_chunk_idx = chunk_idx\n",
    "        self.current_chunk_data = {\n",
    "            'inputs': input_tensors,\n",
    "            'labels': label_tensors,\n",
    "            'masks': mask_tensors,\n",
    "            'start_idx': start_idx\n",
    "        }\n",
    "    \n",
    "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        chunk_idx = idx // self.chunk_size\n",
    "        local_idx = idx % self.chunk_size\n",
    "        \n",
    "        if chunk_idx != self.current_chunk_idx:\n",
    "            self.load_chunk(chunk_idx)\n",
    "        \n",
    "        if local_idx >= len(self.current_chunk_data['inputs']):\n",
    "            raise IndexError(f\"Index {idx} out of range for chunk {chunk_idx}\")\n",
    "        \n",
    "        return (\n",
    "            self.current_chunk_data['inputs'][local_idx],\n",
    "            self.current_chunk_data['labels'][local_idx],\n",
    "            self.current_chunk_data['masks'][local_idx]\n",
    "        )\n",
    "    \n",
    "    def __del__(self):\n",
    "        self.current_chunk_data = None\n",
    "        gc.collect()\n",
    "\n",
    "# =========================\n",
    "# 5. FNO3d Model Architecture\n",
    "# =========================\n",
    "\n",
    "class SpectralConv3d(nn.Module):\n",
    "    \"\"\"\n",
    "    3D Spectral Convolution Layer.\n",
    "    Performs global convolution in the frequency domain.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels: int, out_channels: int, \n",
    "                 modes_t: int, modes_h: int, modes_w: int):\n",
    "        super(SpectralConv3d, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.modes_t = modes_t  # Max modes in time dimension\n",
    "        self.modes_h = modes_h  # Max modes in height dimension\n",
    "        self.modes_w = modes_w  # Max modes in width dimension\n",
    "        \n",
    "        self.scale = 1 / (in_channels * out_channels)\n",
    "        self.weights1 = nn.Parameter(\n",
    "            self.scale * torch.randn(in_channels, out_channels, \n",
    "                                    self.modes_t, self.modes_h, self.modes_w, \n",
    "                                    dtype=torch.cfloat)\n",
    "        )\n",
    "        self.weights2 = nn.Parameter(\n",
    "            self.scale * torch.randn(in_channels, out_channels,\n",
    "                                    self.modes_t, self.modes_h, self.modes_w,\n",
    "                                    dtype=torch.cfloat)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # x shape: (batch, in_channels, T, H, W)\n",
    "        batch_size = x.shape[0]\n",
    "        \n",
    "        # 3D Fourier Transform\n",
    "        x_ft = torch.fft.rfftn(x.float(), dim=(-3, -2, -1))\n",
    "        \n",
    "        # Initialize output tensor in frequency domain\n",
    "        out_ft = torch.zeros(batch_size, self.out_channels, \n",
    "                            x.size(-3), x.size(-2), x.size(-1)//2 + 1,\n",
    "                            dtype=torch.cfloat, device=x.device)\n",
    "        \n",
    "        # Truncate modes\n",
    "        mt = min(self.modes_t, x.size(-3))\n",
    "        mh = min(self.modes_h, x.size(-2))\n",
    "        mw = min(self.modes_w, x.size(-1)//2 + 1)\n",
    "        \n",
    "        # Multiply by weights in frequency domain (low-frequency components)\n",
    "        # Handle positive frequencies\n",
    "        out_ft[:, :, :mt, :mh, :mw] += torch.einsum(\n",
    "            \"bixyz, ioxyz->boxyz\", \n",
    "            x_ft[:, :, :mt, :mh, :mw], \n",
    "            self.weights1[:, :, :mt, :mh, :mw]\n",
    "        )\n",
    "        \n",
    "        # Handle negative frequencies (for time dimension)\n",
    "        out_ft[:, :, -mt:, :mh, :mw] += torch.einsum(\n",
    "            \"bixyz, ioxyz->boxyz\",\n",
    "            x_ft[:, :, -mt:, :mh, :mw],\n",
    "            self.weights2[:, :, :mt, :mh, :mw]\n",
    "        )\n",
    "        \n",
    "        # 3D Inverse Fourier Transform\n",
    "        x = torch.fft.irfftn(out_ft, s=(x.size(-3), x.size(-2), x.size(-1)))\n",
    "        return x\n",
    "\n",
    "class PositionalEncoding3D(nn.Module):\n",
    "    \"\"\"\n",
    "    3D Positional Encoding with caching.\n",
    "    \n",
    "    Generates dynamic positional encodings based on normalized\n",
    "    coordinates (T, H, W) and caches them for efficiency.\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model: int):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        # Term for sin/cos frequencies\n",
    "        self.div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        # Cache for different resolutions\n",
    "        self.pe_cache: Dict[str, torch.Tensor] = {}\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Input shape: (batch, T, C, H, W)\n",
    "        Output shape: (batch, T, H, W, d_model)\n",
    "        \"\"\"\n",
    "        device = x.device\n",
    "        batch, T, C, H, W = x.shape\n",
    "        \n",
    "        cache_key = f\"{T}_{H}_{W}_{device}\"\n",
    "        \n",
    "        if cache_key in self.pe_cache:\n",
    "            # Return cached encoding, expanded to batch size\n",
    "            return self.pe_cache[cache_key][None, ...].expand(batch, -1, -1, -1, -1)\n",
    "        \n",
    "        # Create normalized coordinate grids\n",
    "        pos_t = torch.arange(T, device=device).float() / T\n",
    "        pos_h = torch.arange(H, device=device).float() / H\n",
    "        pos_w = torch.arange(W, device=device).float() / W\n",
    "        \n",
    "        pe = torch.zeros(T, H, W, self.d_model, device=device)\n",
    "        div_term = self.div_term.to(device)\n",
    "        \n",
    "        # Interleave sin/cos, multiplying across dimensions\n",
    "        for i in range(self.d_model // 2):\n",
    "            sin_t = torch.sin(pos_t * div_term[i])\n",
    "            cos_t = torch.cos(pos_t * div_term[i])\n",
    "            sin_h = torch.sin(pos_h * div_term[i])\n",
    "            cos_h = torch.cos(pos_h * div_term[i])\n",
    "            sin_w = torch.sin(pos_w * div_term[i])\n",
    "            cos_w = torch.cos(pos_w * div_term[i])\n",
    "\n",
    "            pe[..., 2*i]   = sin_t[:, None, None] * sin_h[None, :, None] * sin_w[None, None, :]\n",
    "            pe[..., 2*i+1] = cos_t[:, None, None] * cos_h[None, :, None] * cos_w[None, None, :]\n",
    "        \n",
    "        self.pe_cache[cache_key] = pe\n",
    "        \n",
    "        return pe[None, ...].expand(batch, -1, -1, -1, -1)\n",
    "\n",
    "class FNO3d(nn.Module):\n",
    "    \"\"\"\n",
    "    Spatio-temporal Fourier Neural Operator (FNO3d).\n",
    "    \n",
    "    This model processes a sequence of 3D spatio-temporal data (T, H, W)\n",
    "    and predicts the state at the final time step.\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 in_channels: int, \n",
    "                 out_channels: int, \n",
    "                 modes_t: int, \n",
    "                 modes_h: int, \n",
    "                 modes_w: int,\n",
    "                 hidden_channels: int, \n",
    "                 num_layers: int):\n",
    "        super(FNO3d, self).__init__()\n",
    "        \n",
    "        self.pos_encoder = PositionalEncoding3D(hidden_channels)\n",
    "        \n",
    "        # 1. Lifting Layer (P)\n",
    "        # Input channels = in_channels + positional_encoding_dim\n",
    "        self.fc0 = nn.Linear(in_channels + hidden_channels, hidden_channels)\n",
    "        \n",
    "        self.spectral_convs = nn.ModuleList()\n",
    "        self.pointwise_convs = nn.ModuleList()\n",
    "        \n",
    "        # 2. Fourier Layers (Fl)\n",
    "        for _ in range(num_layers):\n",
    "            self.spectral_convs.append(\n",
    "                SpectralConv3d(hidden_channels, hidden_channels, \n",
    "                              modes_t, modes_h, modes_w)\n",
    "            )\n",
    "            # Local path (1x1x1 conv)\n",
    "            self.pointwise_convs.append(\n",
    "                nn.Conv3d(hidden_channels, hidden_channels, 1)\n",
    "            )\n",
    "        \n",
    "        # 3. Projection Layer (Q)\n",
    "        # Predicts from the last time step's features\n",
    "        self.fc1 = nn.Linear(hidden_channels, out_channels)\n",
    "        self.activation = nn.GELU()\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Input shape: (batch, T, C, H, W)\n",
    "        Output shape: (batch, out_channels, H, W)\n",
    "        \"\"\"\n",
    "        batch_size, T, C, H, W = x.shape\n",
    "        \n",
    "        # 1. Add positional encoding\n",
    "        pos_enc = self.pos_encoder(x)  # (batch, T, H, W, hidden)\n",
    "        \n",
    "        # 2. Concatenate features and positional encoding\n",
    "        x = x.permute(0, 1, 3, 4, 2)  # (batch, T, H, W, C)\n",
    "        x = torch.cat([x, pos_enc], dim=-1) # (batch, T, H, W, C + hidden)\n",
    "        \n",
    "        # 3. Lift to hidden dimension\n",
    "        x = self.fc0(x)  # (batch, T, H, W, hidden)\n",
    "        x = x.permute(0, 4, 1, 2, 3)  # (batch, hidden, T, H, W)\n",
    "        \n",
    "        # 4. Apply Fourier Layers\n",
    "        for spec_conv, pw_conv in zip(self.spectral_convs, self.pointwise_convs):\n",
    "            x1 = spec_conv(x)  # Global (frequency) path\n",
    "            x2 = pw_conv(x)    # Local (physical) path\n",
    "            x = self.activation(x1 + x2) # Add & activate\n",
    "        \n",
    "        # 5. Aggregate time (select last time step)\n",
    "        x = x[:, :, -1]  # (batch, hidden, H, W)\n",
    "        \n",
    "        # 6. Project to output\n",
    "        x = x.permute(0, 2, 3, 1)  # (batch, H, W, hidden)\n",
    "        x = self.fc1(x)            # (batch, H, W, out_channels)\n",
    "        x = x.permute(0, 3, 1, 2)  # (batch, out_channels, H, W)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# =========================\n",
    "# 6. Training & Evaluation Functions\n",
    "# =========================\n",
    "\n",
    "def train_one_epoch(model: nn.Module, \n",
    "                    dataloader: DataLoader, \n",
    "                    optimizer: optim.Optimizer, \n",
    "                    criterion: nn.Module, \n",
    "                    device: torch.device, \n",
    "                    epoch: int, \n",
    "                    total_epochs: int, \n",
    "                    memory_cleanup_freq: int = 5) -> Tuple[float, float, float, float]:\n",
    "    \"\"\"\n",
    "    Runs a single training epoch with optimized memory management.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    batch_count = 0\n",
    "    all_preds, all_labels = [], []\n",
    "    start_time = time.time()\n",
    "    \n",
    "    progress_bar = tqdm(dataloader, \n",
    "                       desc=f\"Epoch {epoch}/{total_epochs} [Train]\", \n",
    "                       bar_format=\"{l_bar}{bar:20}{r_bar}\",\n",
    "                       leave=False)\n",
    "    \n",
    "    for batch_idx, (inputs, targets, masks) in enumerate(progress_bar):\n",
    "        inputs = inputs.to(device)  # (B, T, C_in, H, W)\n",
    "        targets = targets.to(device)  # (B, 1, H, W)\n",
    "        masks = masks.to(device)  # (B, 1, H, W)\n",
    "        \n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs)  # (B, 1, H, W)\n",
    "        \n",
    "        # Calculate loss (per-pixel)\n",
    "        loss_tensor = criterion(outputs, targets, masks)\n",
    "        # Aggregate loss only on valid (masked) pixels\n",
    "        masked_loss = loss_tensor.sum() / (masks.sum() + 1e-8)\n",
    "        \n",
    "        # Backward pass\n",
    "        masked_loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += masked_loss.item()\n",
    "        batch_count += 1\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            valid_mask = masks.squeeze(1).bool()\n",
    "            all_preds.append(outputs.detach().squeeze(1)[valid_mask].cpu().numpy())\n",
    "            all_labels.append(targets.squeeze(1)[valid_mask].cpu().numpy())\n",
    "        \n",
    "        del inputs, targets, masks, outputs, loss_tensor, masked_loss\n",
    "        \n",
    "        if (batch_idx + 1) % memory_cleanup_freq == 0:\n",
    "            clean_memory()\n",
    "        \n",
    "        progress_bar.set_postfix({\n",
    "            'Loss': f\"{epoch_loss / (batch_idx + 1):.4f}\",\n",
    "            'LR': f\"{optimizer.param_groups[0]['lr']:.2e}\"\n",
    "        }, refresh=False)\n",
    "    \n",
    "    epoch_duration = time.time() - start_time\n",
    "    avg_loss = epoch_loss / batch_count\n",
    "    \n",
    "    train_r2, train_rmse = 0.0, 0.0\n",
    "    try:\n",
    "        if all_preds and all_labels:\n",
    "            all_preds = np.concatenate(all_preds)\n",
    "            all_labels = np.concatenate(all_labels)\n",
    "            \n",
    "            train_r2 = r2_score(all_labels, all_preds)\n",
    "            train_rmse = np.sqrt(mean_squared_error(all_labels, all_preds))\n",
    "            \n",
    "            del all_preds, all_labels\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error calculating training metrics: {e}\")\n",
    "    \n",
    "    clean_memory()\n",
    "    \n",
    "    return avg_loss, train_r2, train_rmse, epoch_duration\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_and_evaluate(model: nn.Module, \n",
    "                         dataloader: DataLoader, \n",
    "                         device: torch.device, \n",
    "                         batch_size: int = 4, \n",
    "                         memory_cleanup_freq: int = 5) -> Tuple[float, float, float]:\n",
    "    \"\"\"\n",
    "    Optimized prediction and evaluation loop for test sets.\n",
    "    Uses AMP for faster inference and robust memory handling.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    start_time = time.time()\n",
    "    batch_count = 0\n",
    "    \n",
    "    pbar = tqdm(dataloader, \n",
    "               desc=\"Testing [3D]\", \n",
    "               bar_format=\"{l_bar}{bar:20}{r_bar}\",\n",
    "               leave=False)\n",
    "    \n",
    "    # Use Automatic Mixed Precision (AMP) for faster inference\n",
    "    with torch.amp.autocast(device_type='cuda', enabled=torch.cuda.is_available()):\n",
    "        for inputs, labels, masks in pbar:\n",
    "            inputs = inputs.to(device, non_blocking=True)\n",
    "            labels = labels.to(device, non_blocking=True)\n",
    "            masks = masks.to(device, non_blocking=True)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            valid_mask = masks.squeeze(1).bool()\n",
    "            all_preds.append(outputs.squeeze(1)[valid_mask].cpu().numpy())\n",
    "            all_labels.append(labels.squeeze(1)[valid_mask].cpu().numpy())\n",
    "            \n",
    "            batch_count += 1\n",
    "            del inputs, labels, masks, outputs, valid_mask\n",
    "            \n",
    "            if batch_count % memory_cleanup_freq == 0:\n",
    "                clean_memory()\n",
    "                # Consolidate memory if lists get too large\n",
    "                if len(all_preds) > 100:\n",
    "                    all_preds = [np.concatenate(all_preds)]\n",
    "                    all_labels = [np.concatenate(all_labels)]\n",
    "    \n",
    "    r2, rmse = 0.0, float('inf')\n",
    "    try:\n",
    "        if all_preds and all_labels:\n",
    "            all_preds = np.concatenate(all_preds)\n",
    "            all_labels = np.concatenate(all_labels)\n",
    "            \n",
    "            r2 = r2_score(all_labels, all_preds)\n",
    "            rmse = np.sqrt(mean_squared_error(all_labels, all_preds))\n",
    "            \n",
    "            del all_preds, all_labels\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error calculating test metrics: {e}\")\n",
    "    \n",
    "    test_time = time.time() - start_time\n",
    "    clean_memory()\n",
    "    \n",
    "    return r2, rmse, test_time\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_on_training_set(model: nn.Module, \n",
    "                             train_dataset: Dataset, \n",
    "                             device: torch.device, \n",
    "                             batch_size: int = 600, \n",
    "                             memory_cleanup_freq: int = 5) -> Tuple[float, float, float]:\n",
    "    \"\"\"\n",
    "    Evaluates the model on the full training set (post-training).\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    start_time = time.time()\n",
    "    batch_count = 0\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,  # No need to shuffle for evaluation\n",
    "        pin_memory=True,\n",
    "        num_workers=0,  # Use main thread for simplicity\n",
    "    )\n",
    "    \n",
    "    pbar = tqdm(train_loader, \n",
    "               desc=\"Evaluating on Training Set\", \n",
    "               bar_format=\"{l_bar}{bar:20}{r_bar}\",\n",
    "               leave=False)\n",
    "    \n",
    "    with torch.amp.autocast(device_type='cuda', enabled=torch.cuda.is_available()):\n",
    "        for inputs, labels, masks in pbar:\n",
    "            inputs = inputs.to(device, non_blocking=True)\n",
    "            labels = labels.to(device, non_blocking=True)\n",
    "            masks = masks.to(device, non_blocking=True)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            valid_mask = masks.squeeze(1).bool()\n",
    "            all_preds.append(outputs.squeeze(1)[valid_mask].cpu().numpy())\n",
    "            all_labels.append(labels.squeeze(1)[valid_mask].cpu().numpy())\n",
    "            \n",
    "            batch_count += 1\n",
    "            del inputs, labels, masks, outputs, valid_mask\n",
    "            \n",
    "            if batch_count % memory_cleanup_freq == 0:\n",
    "                clean_memory()\n",
    "                if len(all_preds) > 100:\n",
    "                    all_preds = [np.concatenate(all_preds)]\n",
    "                    all_labels = [np.concatenate(all_labels)]\n",
    "\n",
    "    r2, rmse = 0.0, float('inf')\n",
    "    try:\n",
    "        if all_preds and all_labels:\n",
    "            all_preds = np.concatenate(all_preds)\n",
    "            all_labels = np.concatenate(all_labels)\n",
    "            \n",
    "            r2 = r2_score(all_labels, all_preds)\n",
    "            rmse = np.sqrt(mean_squared_error(all_labels, all_preds))\n",
    "            \n",
    "            del all_preds, all_labels\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error calculating full training set metrics: {e}\")\n",
    "    \n",
    "    eval_time = time.time() - start_time\n",
    "    clean_memory()\n",
    "    \n",
    "    return r2, rmse, eval_time\n",
    "\n",
    "# =========================\n",
    "# 7. Main Execution\n",
    "# =========================\n",
    "\n",
    "def get_args() -> argparse.Namespace:\n",
    "    \"\"\"\n",
    "    Parses command-line arguments.\n",
    "    \"\"\"\n",
    "    parser = argparse.ArgumentParser(description=\"FNO3d Training and Evaluation Script\")\n",
    "    \n",
    "    # --- Data Paths ---\n",
    "    parser.add_argument('--train_data_dir', type=str, \n",
    "                        default=\"/home/ubuntu/Documents/xjq/data_Q_timeseries_0329/train_data_LF\",\n",
    "                        help=\"Directory for multi-event training data.\")\n",
    "    parser.add_argument('--test_100m_dir', type=str, \n",
    "                        default=\"/home/ubuntu/Documents/xjq/data_Q_timeseries_0329/test_data_LF\",\n",
    "                        help=\"Directory for 100m (LR) test data.\")\n",
    "    parser.add_argument('--test_30m_dir', type=str, \n",
    "                        default=\"/home/ubuntu/Documents/xjq/data_Q_timeseries_0329/test_data_HF\",\n",
    "                        help=\"Directory for 30m (HR) test data.\")\n",
    "    \n",
    "    # --- Training Parameters ---\n",
    "    parser.add_argument('--num_epochs', type=int, default=20, help=\"Number of training epochs.\")\n",
    "    parser.add_argument('--batch_size', type=int, default=2, help=\"Batch size for training.\")\n",
    "    parser.add_argument('--lr', type=float, default=1e-3, help=\"Learning rate.\")\n",
    "    \n",
    "    # --- Model Hyperparameters (Grid Search) ---\n",
    "    parser.add_argument('--modes_t', type=int, nargs='+', default=[2, 4, 8], \n",
    "                        help=\"List of temporal modes to try.\")\n",
    "    parser.add_argument('--modes_h', type=int, nargs='+', default=[5, 10, 20, 40], \n",
    "                        help=\"List of height modes to try.\")\n",
    "    parser.add_argument('--modes_w', type=int, nargs='+', default=[5, 10, 20, 40], \n",
    "                        help=\"List of width modes to try.\")\n",
    "    parser.add_argument('--hidden_channels', type=int, nargs='+', default=[10, 20, 40], \n",
    "                        help=\"List of hidden channel sizes to try.\")\n",
    "    parser.add_argument('--num_layers', type=int, nargs='+', default=[1, 3, 5], \n",
    "                        help=\"List of layer counts to try.\")\n",
    "    \n",
    "    # --- Loss and Memory Config ---\n",
    "    parser.add_argument('--use_dynamic_loss', action='store_true', \n",
    "                        help=\"Use DynamicWeightedMSELoss instead of standard MSE.\")\n",
    "    parser.add_argument('--use_chunked_loading_hf', action='store_true', \n",
    "                        help=\"Use chunked loading for 30m (HR) test data.\")\n",
    "    parser.add_argument('--hf_chunk_size', type=int, default=300, \n",
    "                        help=\"Chunk size for loading 30m data if chunked loading is enabled.\")\n",
    "    parser.add_argument('--eval_batch_size', type=int, default=60, \n",
    "                        help=\"Batch size for post-training evaluation on the full train set.\")\n",
    "    \n",
    "    # --- System Config ---\n",
    "    parser.add_argument('--num_workers', type=int, default=0, \n",
    "                        help=\"Number of DataLoader workers.\")\n",
    "    \n",
    "    # --- Output Files ---\n",
    "    parser.add_argument('--results_file', type=str, default=\"FNO3D_test_results.csv\",\n",
    "                        help=\"File to save test results.\")\n",
    "    parser.add_argument('--train_eval_file', type=str, default=\"FNO3D_train_eval_results.csv\",\n",
    "                        help=\"File to save full training set evaluation results.\")\n",
    "\n",
    "    return parser.parse_args()\n",
    "\n",
    "def main(args: argparse.Namespace):\n",
    "    \"\"\"\n",
    "    Main training and evaluation loop.\n",
    "    \"\"\"\n",
    "    # 1. Initialization\n",
    "    set_seed(42, deterministic=True)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    logger.info(f\"Using device: {device}\")\n",
    "    \n",
    "    logger.info(\"Initial memory state:\")\n",
    "    print_memory_usage()\n",
    "\n",
    "    # 2. Load Training Dataset\n",
    "    logger.info(\"Loading training dataset...\")\n",
    "    \n",
    "    if os.path.isdir(args.train_data_dir) and len(os.listdir(args.train_data_dir)) > 0:\n",
    "        logger.info(f\"Using multi-event dataset from: {args.train_data_dir}\")\n",
    "        train_dataset = Flood3DMultiEventDataset(args.train_data_dir)\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"Training data directory not found or is empty: {args.train_data_dir}\")\n",
    "        \n",
    "    logger.info(f\"Training dataset size: {len(train_dataset)}\")\n",
    "    \n",
    "    logger.info(\"Memory state after loading training data:\")\n",
    "    print_memory_usage()\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=args.batch_size,\n",
    "        shuffle=True,\n",
    "        pin_memory=True,\n",
    "        num_workers=args.num_workers,\n",
    "        worker_init_fn=seed_worker\n",
    "    )\n",
    "\n",
    "    # 3. Prepare Test Files\n",
    "    def prepare_test_files(test_dir: str) -> List[Tuple[str, str]]:\n",
    "        driver_files = sorted([f for f in os.listdir(test_dir) if f.endswith('_X.h5')])\n",
    "        label_files = sorted([f for f in os.listdir(test_dir) if f.endswith('_Y.h5')])\n",
    "        if len(driver_files) != len(label_files):\n",
    "            raise ValueError(f\"Test file mismatch in {test_dir}\")\n",
    "        return list(zip(driver_files, label_files))\n",
    "\n",
    "    test_100m_files = prepare_test_files(args.test_100m_dir)\n",
    "    test_30m_files = prepare_test_files(args.test_30m_dir)\n",
    "\n",
    "    # 4. Initialize Log Files\n",
    "    test_log_file = args.results_file\n",
    "    with open(test_log_file, 'w') as f:\n",
    "        f.write(\"modes_t,modes_h,modes_w,hidden,layers,resolution,event,r2,rmse,time\\n\")\n",
    "    \n",
    "    train_eval_log_file = args.train_eval_file\n",
    "    with open(train_eval_log_file, 'w') as f:\n",
    "        f.write(\"modes_t,modes_h,modes_w,hidden,layers,train_r2,train_rmse,eval_time\\n\")\n",
    "\n",
    "    # 5. Experiment Grid Search Loop\n",
    "    for modes_t in args.modes_t:\n",
    "        for modes_h in args.modes_h:\n",
    "            for modes_w in args.modes_w:\n",
    "                for hidden in args.hidden_channels:\n",
    "                    for n_layers in args.num_layers:\n",
    "                        \n",
    "                        exp_id = f\"t{modes_t}_h{modes_h}_w{modes_w}_h{hidden}_l{n_layers}\"\n",
    "                        if args.use_dynamic_loss:\n",
    "                            exp_id += \"_dynamic\"\n",
    "                            \n",
    "                        best_model_path = f\"best_model_{exp_id}.pth\"\n",
    "                        \n",
    "                        if os.path.exists(best_model_path):\n",
    "                            logger.info(f\"Model for config ({exp_id}) already exists, skipping.\")\n",
    "                            continue\n",
    "\n",
    "                        train_log_file = f\"train_log_{exp_id}.txt\"\n",
    "                        with open(train_log_file, 'w') as f:\n",
    "                            f.write(\"epoch,train_loss,train_r2,train_rmse,epoch_time\\n\")\n",
    "\n",
    "                        logger.info(f\"Memory state before initializing model {exp_id}:\")\n",
    "                        print_memory_usage()\n",
    "\n",
    "                        # Initialize Model\n",
    "                        model = FNO3d(\n",
    "                            in_channels=7,  # 7 input features\n",
    "                            out_channels=1, # 1 output feature (water depth)\n",
    "                            modes_t=modes_t,\n",
    "                            modes_h=modes_h,\n",
    "                            modes_w=modes_w,\n",
    "                            hidden_channels=hidden,\n",
    "                            num_layers=n_layers\n",
    "                        ).to(device)\n",
    "                        \n",
    "                        # Initialize Loss\n",
    "                        if args.use_dynamic_loss:\n",
    "                            criterion = DynamicWeightedMSELoss(\n",
    "                                update_freq=50 # Example update frequency\n",
    "                            ).to(device)\n",
    "                            logger.info(\"Using Dynamic Weighted MSE Loss\")\n",
    "                        else:\n",
    "                            criterion = StandardMSELoss().to(device)\n",
    "                            logger.info(\"Using Standard MSE Loss\")\n",
    "                        \n",
    "                        optimizer = optim.AdamW(model.parameters(), lr=args.lr, weight_decay=1e-4)\n",
    "                        \n",
    "                        logger.info(f\"\\n=== Starting Training: {exp_id} ===\")\n",
    "                        logger.info(\"Memory state after model initialization:\")\n",
    "                        print_memory_usage()\n",
    "                        \n",
    "                        # --- Training Loop ---\n",
    "                        for epoch in range(1, args.num_epochs + 1):\n",
    "                            train_loss, train_r2, train_rmse, epoch_time = train_one_epoch(\n",
    "                                model, train_loader, optimizer, criterion, device, \n",
    "                                epoch, args.num_epochs,\n",
    "                                memory_cleanup_freq=10\n",
    "                            )\n",
    "                            \n",
    "                            with open(train_log_file, 'a') as f:\n",
    "                                f.write(f\"{epoch},{train_loss:.6f},{train_r2:.4f},{train_rmse:.4f},{epoch_time:.2f}\\n\")\n",
    "                            \n",
    "                            logger.info(f\"Epoch {epoch}/{args.num_epochs}: \"\n",
    "                                       f\"Train Loss={train_loss:.4f}, R2={train_r2:.4f}, RMSE={train_rmse:.4f}, \"\n",
    "                                       f\"Time={epoch_time:.2f}s\")\n",
    "                            \n",
    "                            if epoch % 5 == 0:\n",
    "                                logger.info(f\"Memory state after Epoch {epoch}:\")\n",
    "                                print_memory_usage()\n",
    "                        \n",
    "                        torch.save(model.state_dict(), best_model_path)\n",
    "                        logger.info(f\"Training complete. Saved final model to {best_model_path}\")\n",
    "                        \n",
    "                        logger.info(\"Memory state after training:\")\n",
    "                        print_memory_usage()\n",
    "                        \n",
    "                        # --- Full Training Set Evaluation ---\n",
    "                        logger.info(\"Evaluating model on the full training set...\")\n",
    "                        \n",
    "                        train_r2, train_rmse, train_eval_time = evaluate_on_training_set(\n",
    "                            model, train_dataset, device, \n",
    "                            batch_size=args.eval_batch_size,\n",
    "                            memory_cleanup_freq=10\n",
    "                        )\n",
    "                        \n",
    "                        with open(train_eval_log_file, 'a') as f:\n",
    "                            f.write(f\"{modes_t},{modes_h},{modes_w},{hidden},{n_layers},\"\n",
    "                                   f\"{train_r2:.6f},{train_rmse:.6f},{train_eval_time:.2f}\\n\")\n",
    "                        \n",
    "                        logger.info(f\"Full Train Set Eval: R2={train_r2:.6f}, RMSE={train_rmse:.6f}, Time={train_eval_time:.2f}s\")\n",
    "\n",
    "                        # --- Test Set Evaluation ---\n",
    "                        def run_testing(test_files: List[Tuple[str, str]], test_dir: str, resolution: str):\n",
    "                            for drv_file, lbl_file in test_files:\n",
    "                                event_name = drv_file.replace('_X.h5', '')\n",
    "                                drv_path = os.path.join(test_dir, drv_file)\n",
    "                                lbl_path = os.path.join(test_dir, lbl_file)\n",
    "                                \n",
    "                                logger.info(f\"Memory state before testing event {event_name}:\")\n",
    "                                print_memory_usage()\n",
    "\n",
    "                                # Select dataloader based on resolution and config\n",
    "                                if resolution == \"30m\" and args.use_chunked_loading_hf:\n",
    "                                    logger.info(f\"Using Chunked Loader for {resolution} data\")\n",
    "                                    test_ds = Flood3DChunkedTestDataset(\n",
    "                                        driver_path=drv_path, label_path=lbl_path,\n",
    "                                        driver_key='data', label_key='data',\n",
    "                                        chunk_size=args.hf_chunk_size\n",
    "                                    )\n",
    "                                    test_batch_size = 2 # Smaller batch size for HR data\n",
    "                                else:\n",
    "                                    logger.info(f\"Using Full-Load Loader for {resolution} data\")\n",
    "                                    test_ds = Flood3DTestDataset(\n",
    "                                        driver_path=drv_path, label_path=lbl_path,\n",
    "                                        driver_key='data', label_key='data'\n",
    "                                    )\n",
    "                                    test_batch_size = 4 if resolution == \"100m\" else 2\n",
    "                                    \n",
    "                                test_loader = DataLoader(\n",
    "                                    test_ds, \n",
    "                                    batch_size=test_batch_size, \n",
    "                                    shuffle=False,\n",
    "                                    pin_memory=True,\n",
    "                                    num_workers=0 # Use 0 for chunked/lazy loading\n",
    "                                )\n",
    "\n",
    "                                r2, rmse, test_time = predict_and_evaluate(\n",
    "                                    model, test_loader, device, \n",
    "                                    batch_size=test_batch_size,\n",
    "                                    memory_cleanup_freq=10\n",
    "                                )\n",
    "\n",
    "                                with open(test_log_file, 'a') as f:\n",
    "                                    f.write(f\"{modes_t},{modes_h},{modes_w},{hidden},{n_layers},\"\n",
    "                                           f\"{resolution},{event_name},{r2:.4f},{rmse:.4f},{test_time:.2f}\\n\")\n",
    "                                \n",
    "                                logger.info(f\"Event: {event_name}, Res: {resolution}, \"\n",
    "                                           f\"R2={r2:.4f}, RMSE={rmse:.4f}, Time={test_time:.2f}s\")\n",
    "                                \n",
    "                                del test_ds, test_loader\n",
    "                                clean_memory()\n",
    "\n",
    "                        # Run tests for 100m and 30m\n",
    "                        logger.info(\"Testing on 100m dataset...\")\n",
    "                        run_testing(test_100m_files, args.test_100m_dir, \"100m\")\n",
    "\n",
    "                        logger.info(\"Testing on 30m (ZS-SR) dataset...\")\n",
    "                        run_testing(test_30m_files, args.test_30m_dir, \"30m\")\n",
    "\n",
    "                        # Clean up model from memory\n",
    "                        del model, criterion, optimizer\n",
    "                        clean_memory()\n",
    "                        \n",
    "                        logger.info(f\"Memory state after experiment {exp_id}:\")\n",
    "                        print_memory_usage()\n",
    "\n",
    "    logger.info(f\"\\nAll experiments complete!\")\n",
    "    logger.info(f\"Test results saved to: {test_log_file}\")\n",
    "    logger.info(f\"Training set evaluation results saved to: {train_eval_log_file}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 1. Parse command-line arguments\n",
    "    args = get_args()\n",
    "    \n",
    "    # 2. Log the configuration\n",
    "    logger.info(\"Starting FNO3d run with configuration:\")\n",
    "    logger.info(\"=\" * 30)\n",
    "    for k, v in vars(args).items():\n",
    "        logger.info(f\"{k}: {v}\")\n",
    "    logger.info(\"=\" * 30)\n",
    "    \n",
    "    # 3. Run the main function\n",
    "    main(args)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xjqenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

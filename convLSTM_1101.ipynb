{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "ConvLSTM (Convolutional Long Short-Term Memory) Training and Evaluation Script\n",
    "\n",
    "This script implements a ConvLSTM-based model for flood inundation forecasting,\n",
    "serving as a baseline comparison to architectures like FNO. It includes data\n",
    "loading (multi-event, chunked), model definition (ConvLSTMCell, ConvLSTMFloodModel),\n",
    "custom loss functions, and a full training/evaluation loop with hyperparameter\n",
    "grid search.\n",
    "\n",
    "This code is refactored from a Jupyter Notebook, standardizing it for\n",
    "command-line execution and public release.\n",
    "\n",
    "Key Features:\n",
    "- ConvLSTM model architecture with dynamic 3D positional encoding.\n",
    "- Multiple Dataset classes for different loading strategies:\n",
    "    - Flood3DMultiEventDataset: Loads all training events from a directory.\n",
    "    - Flood3DTestDataset: Loads a full test event into RAM (for 100m data).\n",
    "    - Flood3DChunkedTestDataset: Loads a test event in chunks (for 30m data).\n",
    "- Hyperparameter grid search via command-line arguments.\n",
    "- Robust memory management and logging.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import h5py\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import glob\n",
    "import math\n",
    "import gc\n",
    "import psutil\n",
    "import logging\n",
    "import argparse  # Import argparse for command-line arguments\n",
    "import csv\n",
    "from typing import List, Tuple, Optional, Dict, Any\n",
    "\n",
    "# PyTorch Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Scikit-learn Imports\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# =========================\n",
    "# 1. Memory Management Utilities\n",
    "# =========================\n",
    "\n",
    "def print_memory_usage(logger: logging.Logger):\n",
    "    \"\"\"\n",
    "    Logs the current CPU and GPU memory usage.\n",
    "    \"\"\"\n",
    "    # CPU Memory\n",
    "    process = psutil.Process(os.getpid())\n",
    "    cpu_memory = process.memory_info().rss / (1024 * 1024)  # MB\n",
    "    logger.info(f\"CPU Memory Usage: {cpu_memory:.2f} MB\")\n",
    "    \n",
    "    # GPU Memory (if available)\n",
    "    if torch.cuda.is_available():\n",
    "        for i in range(torch.cuda.device_count()):\n",
    "            reserved = torch.cuda.memory_reserved(i) / (1024 * 1024)  # MB\n",
    "            allocated = torch.cuda.memory_allocated(i) / (1024 * 1024)  # MB\n",
    "            logger.info(f\"GPU:{i} Reserved Memory: {reserved:.2f} MB, Allocated Memory: {allocated:.2f} MB\")\n",
    "\n",
    "def clean_memory():\n",
    "    \"\"\"\n",
    "    Performs garbage collection and empties the CUDA cache.\n",
    "    \"\"\"\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "# =========================\n",
    "# 2. Logging and Seeding Utilities\n",
    "# =========================\n",
    "\n",
    "def setup_logging() -> logging.Logger:\n",
    "    \"\"\"\n",
    "    Configures a global logger.\n",
    "    \"\"\"\n",
    "    logger = logging.getLogger()\n",
    "    logger.setLevel(logging.INFO)\n",
    "    if logger.hasHandlers():\n",
    "        logger.handlers.clear()\n",
    "    \n",
    "    ch = logging.StreamHandler()\n",
    "    ch.setLevel(logging.INFO)\n",
    "    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "    ch.setFormatter(formatter)\n",
    "    logger.addHandler(ch)\n",
    "    return logger\n",
    "\n",
    "# Initialize global logger\n",
    "logger = setup_logging()\n",
    "\n",
    "def set_seed(seed: int = 42, deterministic: bool = True):\n",
    "    \"\"\"\n",
    "    Sets random seeds for reproducibility.\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    if deterministic:\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def seed_worker(worker_id: int):\n",
    "    \"\"\"\n",
    "    Sets the random seed for a DataLoader worker.\n",
    "    \"\"\"\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "# =========================\n",
    "# 3. Custom Loss Functions\n",
    "# =========================\n",
    "\n",
    "class DynamicWeightedMSELoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Dynamic Weighted MSE Loss.\n",
    "    \n",
    "    Applies different weights based on target value percentiles.\n",
    "    Uses a caching mechanism to update thresholds periodically.\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 percentile_thresholds: List[float] = [50, 75, 90], \n",
    "                 weights_multipliers: List[float] = [1.0, 2.0, 5.0, 10.0], \n",
    "                 eps: float = 1e-8,\n",
    "                 update_freq: int = 10):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            percentile_thresholds: List of percentiles (0-100).\n",
    "            weights_multipliers: List of weights, length must be len(thresholds) + 1.\n",
    "            eps: Epsilon for safe division.\n",
    "            update_freq: How often (in batches) to update thresholds.\n",
    "        \"\"\"\n",
    "        super(DynamicWeightedMSELoss, self).__init__()\n",
    "        self.percentile_thresholds = percentile_thresholds\n",
    "        self.weights_multipliers = weights_multipliers\n",
    "        self.eps = eps\n",
    "        self.update_freq = update_freq\n",
    "        \n",
    "        self.thresholds_cache = None\n",
    "        self.call_count = 0\n",
    "        \n",
    "        if len(weights_multipliers) != len(percentile_thresholds) + 1:\n",
    "            raise ValueError(\"Length of weights_multipliers must be len(percentile_thresholds) + 1\")\n",
    "    \n",
    "    def update_thresholds(self, targets: torch.Tensor, mask: Optional[torch.Tensor] = None) -> Optional[List[torch.Tensor]]:\n",
    "        if mask is not None:\n",
    "            valid_targets = targets[mask > 0.5]\n",
    "        else:\n",
    "            valid_targets = targets.reshape(-1)\n",
    "        \n",
    "        if valid_targets.numel() == 0:\n",
    "            return None\n",
    "        \n",
    "        thresholds = [torch.quantile(valid_targets, p / 100.0) for p in self.percentile_thresholds]\n",
    "        return thresholds\n",
    "    \n",
    "    def forward(self, \n",
    "                outputs: torch.Tensor, \n",
    "                targets: torch.Tensor, \n",
    "                mask: Optional[torch.Tensor] = None) -> torch.Tensor:\n",
    "        mse = (outputs - targets) ** 2\n",
    "        \n",
    "        self.call_count += 1\n",
    "        if self.thresholds_cache is None or self.call_count % self.update_freq == 0:\n",
    "            self.thresholds_cache = self.update_thresholds(targets, mask)\n",
    "            \n",
    "        if self.thresholds_cache is None:\n",
    "            return mse\n",
    "        \n",
    "        thresholds = self.thresholds_cache\n",
    "        weights = torch.ones_like(targets) * self.weights_multipliers[0]\n",
    "        \n",
    "        for i in range(len(thresholds)):\n",
    "            if i == 0:\n",
    "                condition = (targets > 0) & (targets <= thresholds[i])\n",
    "            else:\n",
    "                condition = (targets > thresholds[i-1]) & (targets <= thresholds[i])\n",
    "            weights = torch.where(condition, self.weights_multipliers[i], weights)\n",
    "        \n",
    "        weights = torch.where(targets > thresholds[-1], self.weights_multipliers[-1], weights)\n",
    "        \n",
    "        return mse * weights\n",
    "\n",
    "class StandardMSELoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Wrapper for standard nn.MSELoss to match the interface of\n",
    "    DynamicWeightedMSELoss, accepting a mask argument.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(StandardMSELoss, self).__init__()\n",
    "        self.mse = nn.MSELoss(reduction='none')\n",
    "    \n",
    "    def forward(self, \n",
    "                outputs: torch.Tensor, \n",
    "                targets: torch.Tensor, \n",
    "                mask: Optional[torch.Tensor] = None) -> torch.Tensor:\n",
    "        return self.mse(outputs, targets)\n",
    "\n",
    "# =========================\n",
    "# 4. Dataset Classes\n",
    "# =========================\n",
    "\n",
    "class Flood3DMultiEventDataset(Dataset):\n",
    "    \"\"\"\n",
    "    3D Spatio-temporal Dataset for multiple flood events.\n",
    "    Loads all samples from all H5 files in a directory into RAM.\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 data_dir: str, \n",
    "                 time_steps: int = 11, \n",
    "                 transform: Optional[Any] = None, \n",
    "                 driver_key: str = 'data',  # Key was 'data' in convLSTM notebook\n",
    "                 label_key: str = 'data'):\n",
    "        \n",
    "        self.time_steps = time_steps\n",
    "        self.transform = transform\n",
    "        self.driver_key = driver_key\n",
    "        self.label_key = label_key\n",
    "        \n",
    "        driver_files = sorted(glob.glob(os.path.join(data_dir, \"*_X*.h5\")))\n",
    "        label_files = sorted(glob.glob(os.path.join(data_dir, \"*_Y*.h5\")))\n",
    "        \n",
    "        if not driver_files or len(driver_files) != len(label_files):\n",
    "            raise ValueError(f\"Driver/Label file mismatch or not found in {data_dir}\")\n",
    "        \n",
    "        self.input_tensors = []\n",
    "        self.label_tensors = []\n",
    "        self.mask_tensors = []\n",
    "        \n",
    "        for driver_file, label_file in zip(driver_files, label_files):\n",
    "            event_name = os.path.basename(driver_file).split('_X')[0]\n",
    "            logger.info(f\"Loading training event: {event_name}\")\n",
    "            \n",
    "            with h5py.File(driver_file, 'r') as hf:\n",
    "                driver_data = hf[self.driver_key][:]\n",
    "            \n",
    "            with h5py.File(label_file, 'r') as hf:\n",
    "                label_data = hf[self.label_key][:]\n",
    "            \n",
    "            if driver_data.shape[1] != time_steps:\n",
    "                logger.warning(f\"Event {event_name} has {driver_data.shape[1]} time steps, expected {time_steps}. Skipping.\")\n",
    "                continue\n",
    "            \n",
    "            for i in range(driver_data.shape[0]):\n",
    "                driver_sequence = driver_data[i].astype(np.float32)\n",
    "                mask = np.expand_dims(driver_sequence[-1, ..., 4], axis=0)  # (1, H, W)\n",
    "                input_data = np.transpose(driver_sequence, (0, 3, 1, 2))  # (T, C, H, W)\n",
    "                label = np.expand_dims(label_data[i].squeeze(-1), axis=0) # (1, H, W)\n",
    "                \n",
    "                if self.transform:\n",
    "                    input_data, label, mask = self.transform(input_data, label, mask)\n",
    "                \n",
    "                self.input_tensors.append(torch.from_numpy(input_data).float())\n",
    "                self.label_tensors.append(torch.from_numpy(label).float())\n",
    "                self.mask_tensors.append(torch.from_numpy(mask).float())\n",
    "            \n",
    "            del driver_data, label_data\n",
    "            gc.collect()\n",
    "        \n",
    "        self.num_samples = len(self.input_tensors)\n",
    "        logger.info(f\"Loaded {self.num_samples} training samples in total.\")\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return self.num_samples\n",
    "    \n",
    "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        return (\n",
    "            self.input_tensors[idx],\n",
    "            self.label_tensors[idx],\n",
    "            self.mask_tensors[idx]\n",
    "        )\n",
    "\n",
    "class Flood3DTestDataset(Dataset):\n",
    "    \"\"\"\n",
    "    3D Spatio-temporal Test Dataset. Loads entire event into RAM.\n",
    "    Suitable for 100m (LR) data.\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 driver_path: str, \n",
    "                 label_path: str, \n",
    "                 driver_key: str = 'data', \n",
    "                 label_key: str = 'data',\n",
    "                 time_steps: int = 11):\n",
    "        \n",
    "        with h5py.File(driver_path, 'r') as hf:\n",
    "            self.driver_data = hf[driver_key][:]\n",
    "        with h5py.File(label_path, 'r') as hf:\n",
    "            self.label_data = hf[label_key][:]\n",
    "\n",
    "        # Handle single-sample files\n",
    "        if self.driver_data.ndim == 5 and self.driver_data.shape[0] == 1:\n",
    "            self.driver_data = np.expand_dims(self.driver_data[0], axis=0)\n",
    "        if self.label_data.ndim == 4 and self.label_data.shape[0] == 1:\n",
    "            self.label_data = np.expand_dims(self.label_data[0], axis=0)\n",
    "\n",
    "        assert self.driver_data.shape[0] == self.label_data.shape[0], \"Sample count mismatch\"\n",
    "        assert self.driver_data.shape[1] == time_steps, f\"Time steps must be {time_steps}\"\n",
    "\n",
    "        self.num_samples = self.driver_data.shape[0]\n",
    "        self.masks = np.expand_dims(self.driver_data[:, -1, ..., 4], axis=1).astype(np.float32) # (N, 1, H, W)\n",
    "        self.inputs = np.transpose(self.driver_data, (0, 1, 4, 2, 3)).astype(np.float32) # (N, T, C, H, W)\n",
    "        self.labels = self.label_data.astype(np.float32) # (N, H, W, 1)\n",
    "\n",
    "        del self.driver_data, self.label_data\n",
    "        gc.collect()\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.num_samples\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        x = self.inputs[idx]\n",
    "        y = np.expand_dims(self.labels[idx].squeeze(-1), axis=0) # (1, H, W)\n",
    "        m = self.masks[idx]\n",
    "        return torch.from_numpy(x), torch.from_numpy(y), torch.from_numpy(m)\n",
    "\n",
    "class Flood3DChunkedTestDataset(Dataset):\n",
    "    \"\"\"\n",
    "    3D Spatio-temporal Test Dataset with Chunked Loading.\n",
    "    Suitable for 30m (HR) data.\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 driver_path: str, \n",
    "                 label_path: str, \n",
    "                 driver_key: str = 'data', \n",
    "                 label_key: str = 'data',\n",
    "                 time_steps: int = 11, \n",
    "                 chunk_size: int = 4):\n",
    "        \n",
    "        if not os.path.isfile(driver_path):\n",
    "            raise FileNotFoundError(f\"Driver file not found: {driver_path}\")\n",
    "        if not os.path.isfile(label_path):\n",
    "            raise FileNotFoundError(f\"Label file not found: {label_path}\")\n",
    "\n",
    "        self.driver_path = driver_path\n",
    "        self.label_path = label_path\n",
    "        self.driver_key = driver_key\n",
    "        self.label_key = label_key\n",
    "        self.time_steps = time_steps\n",
    "        self.chunk_size = chunk_size\n",
    "        \n",
    "        with h5py.File(driver_path, 'r') as hf:\n",
    "            data_shape = hf[driver_key].shape\n",
    "            self.num_samples = 1 if (len(data_shape) == 5 and data_shape[0] == 1) else data_shape[0]\n",
    "        \n",
    "        self.current_chunk_idx = -1\n",
    "        self.current_chunk_data = None\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.num_samples\n",
    "    \n",
    "    def load_chunk(self, chunk_idx: int):\n",
    "        start_idx = chunk_idx * self.chunk_size\n",
    "        end_idx = min(start_idx + self.chunk_size, self.num_samples)\n",
    "        \n",
    "        logger.info(f\"Loading data chunk {chunk_idx}, samples: {start_idx} to {end_idx-1}\")\n",
    "        \n",
    "        if self.current_chunk_data is not None:\n",
    "            del self.current_chunk_data\n",
    "            clean_memory()\n",
    "        \n",
    "        with h5py.File(self.driver_path, 'r') as hf:\n",
    "            driver_data = np.expand_dims(hf[self.driver_key][0], axis=0) if self.num_samples == 1 else hf[self.driver_key][start_idx:end_idx]\n",
    "        \n",
    "        with h5py.File(self.label_path, 'r') as hf:\n",
    "            label_data = np.expand_dims(hf[self.label_key][0], axis=0) if self.num_samples == 1 else hf[self.label_key][start_idx:end_idx]\n",
    "        \n",
    "        driver_data = driver_data.astype(np.float32)\n",
    "        label_data = label_data.astype(np.float32)\n",
    "        \n",
    "        input_tensors, label_tensors, mask_tensors = [], [], []\n",
    "        \n",
    "        for i in range(driver_data.shape[0]):\n",
    "            mask = np.expand_dims(driver_data[i, -1, ..., 4], axis=0)  # (1, H, W)\n",
    "            input_data = np.transpose(driver_data[i], (0, 3, 1, 2))  # (T, C, H, W)\n",
    "            label_sample = np.expand_dims(label_data[i].squeeze(-1), 0)  # (1, H, W)\n",
    "            \n",
    "            input_tensors.append(torch.from_numpy(input_data).float())\n",
    "            label_tensors.append(torch.from_numpy(label_sample).float())\n",
    "            mask_tensors.append(torch.from_numpy(mask).float())\n",
    "        \n",
    "        del driver_data, label_data\n",
    "        gc.collect()\n",
    "        \n",
    "        self.current_chunk_idx = chunk_idx\n",
    "        self.current_chunk_data = {\n",
    "            'inputs': input_tensors,\n",
    "            'labels': label_tensors,\n",
    "            'masks': mask_tensors,\n",
    "            'start_idx': start_idx\n",
    "        }\n",
    "    \n",
    "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        chunk_idx = idx // self.chunk_size\n",
    "        local_idx = idx % self.chunk_size\n",
    "        \n",
    "        if chunk_idx != self.current_chunk_idx:\n",
    "            self.load_chunk(chunk_idx)\n",
    "        \n",
    "        if local_idx >= len(self.current_chunk_data['inputs']):\n",
    "            raise IndexError(f\"Index {idx} out of range for chunk {chunk_idx}\")\n",
    "        \n",
    "        return (\n",
    "            self.current_chunk_data['inputs'][local_idx],\n",
    "            self.current_chunk_data['labels'][local_idx],\n",
    "            self.current_chunk_data['masks'][local_idx]\n",
    "        )\n",
    "    \n",
    "    def __del__(self):\n",
    "        self.current_chunk_data = None\n",
    "        gc.collect()\n",
    "\n",
    "# =========================\n",
    "# 5. ConvLSTM Model Architecture\n",
    "# =========================\n",
    "\n",
    "class PositionalEncoding3D(nn.Module):\n",
    "    \"\"\"\n",
    "    3D Positional Encoding with caching (same as in FNO script).\n",
    "    \n",
    "    Generates dynamic positional encodings based on normalized\n",
    "    coordinates (T, H, W) and caches them for efficiency.\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model: int):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        self.pe_cache: Dict[str, torch.Tensor] = {}\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Input shape: (batch, T, C, H, W)\n",
    "        Output shape: (batch, T, H, W, d_model)\n",
    "        \"\"\"\n",
    "        device = x.device\n",
    "        batch, T, C, H, W = x.shape\n",
    "        cache_key = f\"{T}_{H}_{W}_{device}\"\n",
    "        \n",
    "        if cache_key in self.pe_cache:\n",
    "            return self.pe_cache[cache_key][None, ...].expand(batch, -1, -1, -1, -1)\n",
    "        \n",
    "        pos_t = (torch.arange(T, device=device).float() / T)\n",
    "        pos_h = (torch.arange(H, device=device).float() / H)\n",
    "        pos_w = (torch.arange(W, device=device).float() / W)\n",
    "        \n",
    "        pe = torch.zeros(T, H, W, self.d_model, device=device)\n",
    "        div_term = self.div_term.to(device)\n",
    "        \n",
    "        for i in range(self.d_model // 2):\n",
    "            sin_t, cos_t = torch.sin(pos_t * div_term[i]), torch.cos(pos_t * div_term[i])\n",
    "            sin_h, cos_h = torch.sin(pos_h * div_term[i]), torch.cos(pos_h * div_term[i])\n",
    "            sin_w, cos_w = torch.sin(pos_w * div_term[i]), torch.cos(pos_w * div_term[i])\n",
    "\n",
    "            pe[..., 2*i]   = sin_t[:, None, None] * sin_h[None, :, None] * sin_w[None, None, :]\n",
    "            pe[..., 2*i+1] = cos_t[:, None, None] * cos_h[None, :, None] * cos_w[None, None, :]\n",
    "        \n",
    "        self.pe_cache[cache_key] = pe\n",
    "        return pe[None, ...].expand(batch, -1, -1, -1, -1)\n",
    "\n",
    "class ConvLSTMCell(nn.Module):\n",
    "    \"\"\"\n",
    "    A single ConvLSTM cell.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_channels: int, hidden_channels: int, \n",
    "                 kernel_size: int, padding: int):\n",
    "        super(ConvLSTMCell, self).__init__()\n",
    "        \n",
    "        self.input_channels = input_channels\n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.padding = padding\n",
    "        \n",
    "        # Convolutions for input-to-hidden and hidden-to-hidden\n",
    "        self.conv = nn.Conv2d(\n",
    "            in_channels=self.input_channels + self.hidden_channels,\n",
    "            out_channels=4 * self.hidden_channels,  # i, f, g, o gates\n",
    "            kernel_size=self.kernel_size,\n",
    "            padding=self.padding\n",
    "        )\n",
    "\n",
    "        # Initialize forget gate bias to 1 for better initial memory\n",
    "        self.conv.bias.data[hidden_channels:2*hidden_channels].fill_(1.0)\n",
    "        \n",
    "    def forward(self, x: torch.Tensor, \n",
    "              h_prev: torch.Tensor, \n",
    "              c_prev: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Single forward pass of the ConvLSTM cell.\n",
    "        \n",
    "        Args:\n",
    "            x: Input tensor [B, C_in, H, W]\n",
    "            h_prev: Previous hidden state [B, C_hidden, H, W]\n",
    "            c_prev: Previous cell state [B, C_hidden, H, W]\n",
    "            \n",
    "        Returns:\n",
    "            h_next: Next hidden state\n",
    "            c_next: Next cell state\n",
    "        \"\"\"\n",
    "        combined = torch.cat([x, h_prev], dim=1)  # Concatenate along channel dim\n",
    "        combined_conv = self.conv(combined)\n",
    "        \n",
    "        # Split into i, f, g, o gates\n",
    "        cc_i, cc_f, cc_g, cc_o = torch.split(combined_conv, self.hidden_channels, dim=1)\n",
    "        \n",
    "        i = torch.sigmoid(cc_i)\n",
    "        f = torch.sigmoid(cc_f)\n",
    "        g = torch.tanh(cc_g)\n",
    "        o = torch.sigmoid(cc_o)\n",
    "        \n",
    "        c_next = f * c_prev + i * g\n",
    "        h_next = o * torch.tanh(c_next)\n",
    "        \n",
    "        return h_next, c_next\n",
    "\n",
    "class ConvLSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    Multi-layer ConvLSTM network.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_channels: int, hidden_channels: int, \n",
    "                 kernel_size: int, num_layers: int, dropout: float = 0.0):\n",
    "        super(ConvLSTM, self).__init__()\n",
    "        \n",
    "        self.input_channels = input_channels\n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "        self.padding = kernel_size // 2\n",
    "        \n",
    "        self.cell_list = nn.ModuleList()\n",
    "        \n",
    "        # First layer\n",
    "        self.cell_list.append(\n",
    "            ConvLSTMCell(input_channels, hidden_channels, kernel_size, self.padding)\n",
    "        )\n",
    "        \n",
    "        # Subsequent layers\n",
    "        for _ in range(1, num_layers):\n",
    "            self.cell_list.append(\n",
    "                ConvLSTMCell(hidden_channels, hidden_channels, kernel_size, self.padding)\n",
    "            )\n",
    "        \n",
    "        self.dropout_layer = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, input_tensor: torch.Tensor) -> List[Tuple[torch.Tensor, torch.Tensor]]:\n",
    "        \"\"\"\n",
    "        Forward pass for the multi-layer ConvLSTM.\n",
    "        \n",
    "        Args:\n",
    "            input_tensor: [B, T, C_in, H, W]\n",
    "            \n",
    "        Returns:\n",
    "            last_state_list: List of (h, c) tuples for each layer at the last time step.\n",
    "        \"\"\"\n",
    "        batch_size, seq_len, _, height, width = input_tensor.size()\n",
    "        \n",
    "        # Initialize hidden and cell states\n",
    "        h_list, c_list = [], []\n",
    "        for _ in range(self.num_layers):\n",
    "            h, c = self._init_hidden(batch_size, height, width, input_tensor.device)\n",
    "            h_list.append(h)\n",
    "            c_list.append(c)\n",
    "        \n",
    "        # Iterate over time steps\n",
    "        for t in range(seq_len):\n",
    "            current_input = input_tensor[:, t, :, :, :]\n",
    "            \n",
    "            for layer_idx in range(self.num_layers):\n",
    "                h, c = h_list[layer_idx], c_list[layer_idx]\n",
    "                \n",
    "                # Input for the current layer\n",
    "                if layer_idx == 0:\n",
    "                    layer_input = current_input\n",
    "                else:\n",
    "                    # Apply dropout between layers\n",
    "                    layer_input = self.dropout_layer(h_list[layer_idx-1])\n",
    "                \n",
    "                h_list[layer_idx], c_list[layer_idx] = self.cell_list[layer_idx](\n",
    "                    layer_input, h, c\n",
    "                )\n",
    "        \n",
    "        # Collect last states\n",
    "        last_state_list = [(h_list[i], c_list[i]) for i in range(self.num_layers)]\n",
    "            \n",
    "        return last_state_list\n",
    "    \n",
    "    def _init_hidden(self, batch_size: int, height: int, width: int, \n",
    "                     device: torch.device) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"Initializes hidden and cell states to zeros.\"\"\"\n",
    "        return (torch.zeros(batch_size, self.hidden_channels, height, width, device=device),\n",
    "                torch.zeros(batch_size, self.hidden_channels, height, width, device=device))\n",
    "\n",
    "class ConvLSTMFloodModel(nn.Module):\n",
    "    \"\"\"\n",
    "    The complete ConvLSTM model for flood prediction, including\n",
    "    positional encoding and input/output layers.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels: int, out_channels: int, \n",
    "                 hidden_channels: int, num_layers: int, \n",
    "                 kernel_size: int = 3, dropout: float = 0.2):\n",
    "        super(ConvLSTMFloodModel, self).__init__()\n",
    "        \n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.num_layers = num_layers\n",
    "        self.kernel_size = kernel_size\n",
    "        \n",
    "        self.pos_encoder = PositionalEncoding3D(hidden_channels)\n",
    "        \n",
    "        # 1. Lifting Layer (P)\n",
    "        self.fc0 = nn.Linear(in_channels + hidden_channels, hidden_channels)\n",
    "        \n",
    "        # 2. ConvLSTM core\n",
    "        self.convlstm = ConvLSTM(\n",
    "            input_channels=hidden_channels,\n",
    "            hidden_channels=hidden_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            num_layers=num_layers,\n",
    "            dropout=dropout\n",
    "        )\n",
    "        \n",
    "        # 3. Projection Layer (Q)\n",
    "        self.conv_out = nn.Conv2d(hidden_channels, out_channels, kernel_size=1)\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Input shape: (batch, T, C, H, W)\n",
    "        Output shape: (batch, out_channels, H, W)\n",
    "        \"\"\"\n",
    "        batch_size, T, C, H, W = x.shape\n",
    "        \n",
    "        # 1. Add positional encoding\n",
    "        pos_enc = self.pos_encoder(x)  # (batch, T, H, W, hidden)\n",
    "        \n",
    "        # 2. Concatenate features and positional encoding\n",
    "        x = x.permute(0, 1, 3, 4, 2)  # (batch, T, H, W, C)\n",
    "        x = torch.cat([x, pos_enc], dim=-1) # (batch, T, H, W, C + hidden)\n",
    "        \n",
    "        # 3. Lift to hidden dimension\n",
    "        x = self.fc0(x)  # (batch, T, H, W, hidden)\n",
    "        \n",
    "        # 4. Permute for ConvLSTM\n",
    "        x = x.permute(0, 1, 4, 2, 3)  # (batch, T, hidden, H, W)\n",
    "        \n",
    "        # 5. Apply ConvLSTM\n",
    "        last_states = self.convlstm(x)\n",
    "        \n",
    "        # 6. Get last hidden state from the last layer\n",
    "        h_last = last_states[-1][0]  # (batch, hidden, H, W)\n",
    "        \n",
    "        # 7. Project to output\n",
    "        output = self.conv_out(h_last)  # (batch, out_channels, H, W)\n",
    "        \n",
    "        return output\n",
    "\n",
    "# =========================\n",
    "# 6. Training & Evaluation Functions\n",
    "# =========================\n",
    "\n",
    "def train_one_epoch(model: nn.Module, \n",
    "                    dataloader: DataLoader, \n",
    "                    optimizer: optim.Optimizer, \n",
    "                    criterion: nn.Module, \n",
    "                    device: torch.device, \n",
    "                    epoch: int, \n",
    "                    total_epochs: int) -> Tuple[float, float, float, float]:\n",
    "    \"\"\"\n",
    "    Runs a single training epoch.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    all_preds, all_labels = [], []\n",
    "    start_time = time.time()\n",
    "    \n",
    "    progress_bar = tqdm(dataloader, \n",
    "                       desc=f\"Epoch {epoch}/{total_epochs} [ConvLSTM]\", \n",
    "                       bar_format=\"{l_bar}{bar:20}{r_bar}\",\n",
    "                       leave=False)\n",
    "    \n",
    "    for batch_idx, (inputs, targets, masks) in enumerate(progress_bar):\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        masks = masks.to(device)\n",
    "        \n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # Calculate per-pixel loss\n",
    "        if isinstance(criterion, DynamicWeightedMSELoss):\n",
    "            loss_tensor = criterion(outputs, targets, masks)\n",
    "        else:\n",
    "            # StandardMSELoss or nn.MSELoss(reduction='none')\n",
    "            loss_tensor = criterion(outputs, targets, mask=masks if isinstance(criterion, StandardMSELoss) else None)\n",
    "        \n",
    "        # Apply mask for standard MSE\n",
    "        if not isinstance(criterion, DynamicWeightedMSELoss):\n",
    "             loss_tensor = loss_tensor * masks\n",
    "\n",
    "        # Aggregate loss over valid pixels\n",
    "        masked_loss = loss_tensor.sum() / (masks.sum() + 1e-8)\n",
    "        \n",
    "        masked_loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += masked_loss.item()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            valid_mask = masks.squeeze(1).bool()\n",
    "            all_preds.append(outputs.detach().squeeze(1)[valid_mask].cpu().numpy())\n",
    "            all_labels.append(targets.squeeze(1)[valid_mask].cpu().numpy())\n",
    "        \n",
    "        progress_bar.set_postfix({\n",
    "            'Loss': f\"{masked_loss.item():.4f}\",\n",
    "            'LR': f\"{optimizer.param_groups[0]['lr']:.2e}\"\n",
    "        }, refresh=False)\n",
    "        \n",
    "        del inputs, targets, masks, outputs, loss_tensor, masked_loss\n",
    "        if batch_idx % 10 == 0:\n",
    "            clean_memory()\n",
    "    \n",
    "    epoch_duration = time.time() - start_time\n",
    "    avg_loss = epoch_loss / (batch_idx + 1)\n",
    "    \n",
    "    train_r2, train_rmse = 0.0, 0.0\n",
    "    try:\n",
    "        if all_preds and all_labels:\n",
    "            all_preds = np.concatenate(all_preds)\n",
    "            all_labels = np.concatenate(all_labels)\n",
    "            train_r2 = r2_score(all_labels, all_preds)\n",
    "            train_rmse = np.sqrt(mean_squared_error(all_labels, all_preds))\n",
    "            del all_preds, all_labels\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error calculating training metrics: {e}\")\n",
    "    \n",
    "    clean_memory()\n",
    "    return avg_loss, train_r2, train_rmse, epoch_duration\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_and_evaluate(model: nn.Module, \n",
    "                         dataloader: DataLoader, \n",
    "                         device: torch.device) -> Tuple[float, float, float]:\n",
    "    \"\"\"\n",
    "    Optimized prediction and evaluation loop for test sets.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    start_time = time.time()\n",
    "    \n",
    "    pbar = tqdm(dataloader, \n",
    "               desc=\"Testing [ConvLSTM]\", \n",
    "               bar_format=\"{l_bar}{bar:20}{r_bar}\",\n",
    "               leave=False)\n",
    "    \n",
    "    with torch.amp.autocast(device_type='cuda', enabled=torch.cuda.is_available()):\n",
    "        for inputs, labels, masks in pbar:\n",
    "            inputs = inputs.to(device, non_blocking=True)\n",
    "            labels = labels.to(device, non_blocking=True)\n",
    "            masks = masks.to(device, non_blocking=True)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            valid_mask = masks.squeeze(1).bool()\n",
    "            all_preds.append(outputs.squeeze(1)[valid_mask].cpu().numpy())\n",
    "            all_labels.append(labels.squeeze(1)[valid_mask].cpu().numpy())\n",
    "            \n",
    "            del inputs, labels, masks, outputs\n",
    "            clean_memory()\n",
    "    \n",
    "    r2, rmse = 0.0, float('inf')\n",
    "    try:\n",
    "        if all_preds and all_labels:\n",
    "            all_preds = np.concatenate(all_preds)\n",
    "            all_labels = np.concatenate(all_labels)\n",
    "            r2 = r2_score(all_labels, all_preds)\n",
    "            rmse = np.sqrt(mean_squared_error(all_labels, all_preds))\n",
    "            del all_preds, all_labels\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error calculating test metrics: {e}\")\n",
    "    \n",
    "    test_time = time.time() - start_time\n",
    "    clean_memory()\n",
    "    return r2, rmse, test_time\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_on_training_set(model: nn.Module, \n",
    "                             train_dataset: Dataset, \n",
    "                             device: torch.device, \n",
    "                             batch_size: int = 100) -> Tuple[float, float, float]:\n",
    "    \"\"\"\n",
    "    Evaluates the model on the full training set (post-training).\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        pin_memory=True,\n",
    "        num_workers=0,\n",
    "    )\n",
    "    \n",
    "    pbar = tqdm(train_loader, \n",
    "               desc=\"Evaluating on Training Set [ConvLSTM]\", \n",
    "               bar_format=\"{l_bar}{bar:20}{r_bar}\",\n",
    "               leave=False)\n",
    "    \n",
    "    with torch.amp.autocast(device_type='cuda', enabled=torch.cuda.is_available()):\n",
    "        for inputs, labels, masks in pbar:\n",
    "            inputs = inputs.to(device, non_blocking=True)\n",
    "            labels = labels.to(device, non_blocking=True)\n",
    "            masks = masks.to(device, non_blocking=True)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            valid_mask = masks.squeeze(1).bool()\n",
    "            all_preds.append(outputs.squeeze(1)[valid_mask].cpu().numpy())\n",
    "            all_labels.append(labels.squeeze(1)[valid_mask].cpu().numpy())\n",
    "            \n",
    "            del inputs, labels, masks, outputs\n",
    "            if len(all_preds) % 10 == 0:\n",
    "                clean_memory()\n",
    "\n",
    "    r2, rmse = 0.0, float('inf')\n",
    "    try:\n",
    "        if all_preds and all_labels:\n",
    "            all_preds = np.concatenate(all_preds)\n",
    "            all_labels = np.concatenate(all_labels)\n",
    "            r2 = r2_score(all_labels, all_preds)\n",
    "            rmse = np.sqrt(mean_squared_error(all_labels, all_preds))\n",
    "            del all_preds, all_labels\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error calculating full training set metrics: {e}\")\n",
    "    \n",
    "    eval_time = time.time() - start_time\n",
    "    clean_memory()\n",
    "    return r2, rmse, eval_time\n",
    "\n",
    "# =========================\n",
    "# 7. Main Execution\n",
    "# =========================\n",
    "\n",
    "def get_args() -> argparse.Namespace:\n",
    "    \"\"\"\n",
    "    Parses command-line arguments.\n",
    "    \"\"\"\n",
    "    parser = argparse.ArgumentParser(description=\"ConvLSTM Training and Evaluation Script\")\n",
    "    \n",
    "    # --- Data Paths ---\n",
    "    parser.add_argument('--train_data_dir', type=str, \n",
    "                        default=\"/home/ubuntu/Documents/xjq/data_Q_timeseries_0329/train_data_LF\",\n",
    "                        help=\"Directory for multi-event training data.\")\n",
    "    parser.add_argument('--test_100m_dir', type=str, \n",
    "                        default=\"/home/ubuntu/Documents/xjq/data_Q_timeseries_0329/test_data_LF\",\n",
    "                        help=\"Directory for 100m (LR) test data.\")\n",
    "    parser.add_argument('--test_30m_dir', type=str, \n",
    "                        default=\"/home/ubuntu/Documents/xjq/data_Q_timeseries_0329/test_data_HF\",\n",
    "                        help=\"Directory for 30m (HR) test data.\")\n",
    "    \n",
    "    # --- Training Parameters ---\n",
    "    parser.add_argument('--num_epochs', type=int, default=20, help=\"Number of training epochs.\")\n",
    "    parser.add_argument('--batch_size', type=int, default=2, help=\"Batch size for training.\")\n",
    "    parser.add_argument('--lr', type=float, default=1e-3, help=\"Learning rate.\")\n",
    "    parser.add_argument('--dropout', type=float, default=0.1, help=\"Dropout rate in ConvLSTM.\")\n",
    "    \n",
    "    # --- Model Hyperparameters (Grid Search) ---\n",
    "    parser.add_argument('--kernel_size', type=int, nargs='+', default=[3, 5, 7], \n",
    "                        help=\"List of kernel sizes to try.\")\n",
    "    parser.add_argument('--hidden_channels', type=int, nargs='+', default=[8, 16, 32, 64], \n",
    "                        help=\"List of hidden channel sizes to try.\")\n",
    "    parser.add_argument('--num_layers', type=int, nargs='+', default=[1, 2, 3, 4, 5], \n",
    "                        help=\"List of layer counts to try.\")\n",
    "    \n",
    "    # --- Loss and Memory Config ---\n",
    "    parser.add_argument('--use_dynamic_loss', action='store_true', \n",
    "                        help=\"Use DynamicWeightedMSELoss instead of standard MSE.\")\n",
    "    parser.add_argument('--hf_chunk_size', type=int, default=10, \n",
    "                        help=\"Chunk size for loading 30m data (must use chunked loader for 30m).\")\n",
    "    parser.add_argument('--eval_batch_size', type=int, default=100, \n",
    "                        help=\"Batch size for post-training evaluation on the full train set.\")\n",
    "    \n",
    "    # --- System Config ---\n",
    "    parser.add_argument('--num_workers', type=int, default=0, \n",
    "                        help=\"Number of DataLoader workers (recommend 0).\")\n",
    "    \n",
    "    # --- Output Files ---\n",
    "    parser.add_argument('--results_file', type=str, default=\"ConvLSTM_test_results.csv\",\n",
    "                        help=\"File to save test results.\")\n",
    "    parser.add_argument('--train_eval_file', type=str, default=\"ConvLSTM_train_eval_results.csv\",\n",
    "                        help=\"File to save full training set evaluation results.\")\n",
    "\n",
    "    return parser.parse_args()\n",
    "\n",
    "def main(args: argparse.Namespace):\n",
    "    \"\"\"\n",
    "    Main training and evaluation loop for ConvLSTM.\n",
    "    \"\"\"\n",
    "    # 1. Initialization\n",
    "    set_seed(42, deterministic=True)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    logger.info(f\"Using device: {device}\")\n",
    "    logger.info(\"Initial memory state:\")\n",
    "    print_memory_usage()\n",
    "\n",
    "    # 2. Load Training Dataset\n",
    "    logger.info(f\"Loading training dataset from: {args.train_data_dir}\")\n",
    "    full_dataset = Flood3DMultiEventDataset(args.train_data_dir, driver_key='data', label_key='data')\n",
    "    logger.info(f\"Training dataset size: {len(full_dataset)}\")\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        full_dataset,\n",
    "        batch_size=args.batch_size,\n",
    "        shuffle=True,\n",
    "        pin_memory=True,\n",
    "        num_workers=args.num_workers,\n",
    "        worker_init_fn=seed_worker\n",
    "    )\n",
    "\n",
    "    # 3. Prepare Test Files\n",
    "    def prepare_test_files(test_dir: str) -> List[Tuple[str, str]]:\n",
    "        driver_files = sorted([f for f in os.listdir(test_dir) if f.endswith('_X.h5')])\n",
    "        label_files = sorted([f for f in os.listdir(test_dir) if f.endswith('_Y.h5')])\n",
    "        if len(driver_files) != len(label_files):\n",
    "            raise ValueError(f\"Test file mismatch in {test_dir}\")\n",
    "        return list(zip(driver_files, label_files))\n",
    "\n",
    "    test_100m_files = prepare_test_files(args.test_100m_dir)\n",
    "    test_30m_files = prepare_test_files(args.test_30m_dir)\n",
    "\n",
    "    # 4. Initialize Log Files\n",
    "    loss_name = \"dynamic\" if args.use_dynamic_loss else \"mse\"\n",
    "    test_log_file = args.results_file.replace(\".csv\", f\"_{loss_name}.csv\")\n",
    "    train_eval_log_file = args.train_eval_file.replace(\".csv\", f\"_{loss_name}.csv\")\n",
    "    \n",
    "    test_log_header = [\"kernel_size\", \"hidden\", \"layers\", \"resolution\", \"event\", \"test_r2\", \"test_rmse\", \"pred_time\"]\n",
    "    train_eval_header = [\"kernel_size\", \"hidden\", \"layers\", \"train_r2\", \"train_rmse\", \"eval_time\"]\n",
    "    \n",
    "    with open(test_log_file, 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(test_log_header)\n",
    "    \n",
    "    with open(train_eval_log_file, 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(train_eval_header)\n",
    "\n",
    "    # 5. Experiment Grid Search Loop\n",
    "    for kernel_size in args.kernel_size:\n",
    "        for hidden in args.hidden_channels:\n",
    "            for n_layers in args.num_layers:\n",
    "                \n",
    "                exp_id = f\"ks{kernel_size}_h{hidden}_l{n_layers}_{loss_name}\"\n",
    "                final_model_path = f\"final_ConvLSTM_model_{exp_id}.pth\"\n",
    "                \n",
    "                if os.path.exists(final_model_path):\n",
    "                    logger.info(f\"Model for config ({exp_id}) already exists, skipping.\")\n",
    "                    continue\n",
    "\n",
    "                train_log_file = f\"train_log_ConvLSTM_{exp_id}.csv\"\n",
    "                train_log_header = [\"kernel_size\", \"hidden\", \"layers\", \"epoch\", \"train_loss\", \"train_r2\", \"train_rmse\", \"epoch_time\"]\n",
    "                with open(train_log_file, 'w', newline='') as f:\n",
    "                    writer = csv.writer(f)\n",
    "                    writer.writerow(train_log_header)\n",
    "\n",
    "                # Initialize Model\n",
    "                model = ConvLSTMFloodModel(\n",
    "                    in_channels=7,\n",
    "                    out_channels=1,\n",
    "                    hidden_channels=hidden,\n",
    "                    num_layers=n_layers,\n",
    "                    kernel_size=kernel_size,\n",
    "                    dropout=args.dropout\n",
    "                ).to(device)\n",
    "                \n",
    "                # Initialize Loss\n",
    "                if args.use_dynamic_loss:\n",
    "                    criterion = DynamicWeightedMSELoss().to(device)\n",
    "                    logger.info(\"Using Dynamic Weighted MSE Loss\")\n",
    "                else:\n",
    "                    criterion = StandardMSELoss().to(device)\n",
    "                    logger.info(\"Using Standard MSE Loss\")\n",
    "                \n",
    "                optimizer = optim.AdamW(model.parameters(), lr=args.lr, weight_decay=1e-4)\n",
    "                scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)\n",
    "\n",
    "                logger.info(f\"\\n=== Starting Training: {exp_id} ===\")\n",
    "                logger.info(\"Memory state after model initialization:\")\n",
    "                print_memory_usage()\n",
    "                \n",
    "                best_train_loss = float('inf')\n",
    "                \n",
    "                # --- Training Loop ---\n",
    "                for epoch in range(1, args.num_epochs + 1):\n",
    "                    train_loss, train_r2, train_rmse, epoch_time = train_one_epoch(\n",
    "                        model, train_loader, optimizer, criterion, device, epoch, args.num_epochs\n",
    "                    )\n",
    "                    \n",
    "                    with open(train_log_file, 'a', newline='') as f:\n",
    "                        writer = csv.writer(f)\n",
    "                        writer.writerow([\n",
    "                            kernel_size, hidden, n_layers, epoch, \n",
    "                            f\"{train_loss:.6f}\", f\"{train_r2:.4f}\", f\"{train_rmse:.4f}\", f\"{epoch_time:.2f}\"\n",
    "                        ])\n",
    "                    \n",
    "                    logger.info(f\"Epoch {epoch}/{args.num_epochs}: \"\n",
    "                               f\"Loss={train_loss:.4f}, R2={train_r2:.4f}, RMSE={train_rmse:.4f}, \"\n",
    "                               f\"Time={epoch_time:.2f}s\")\n",
    "\n",
    "                    scheduler.step(train_loss)\n",
    "                    \n",
    "                    if train_loss < best_train_loss:\n",
    "                        best_train_loss = train_loss\n",
    "                        torch.save(model.state_dict(), final_model_path)\n",
    "                        logger.info(f\"Saved best model (Train Loss: {train_loss:.4f})\")\n",
    "                \n",
    "                # --- Post-Training Evaluation ---\n",
    "                logger.info(f\"Loading best model from {final_model_path} for evaluation.\")\n",
    "                model.load_state_dict(torch.load(final_model_path))\n",
    "                \n",
    "                logger.info(\"Evaluating model on the full training set...\")\n",
    "                train_eval_r2, train_eval_rmse, train_eval_time = evaluate_on_training_set(\n",
    "                    model, full_dataset, device, batch_size=args.eval_batch_size\n",
    "                )\n",
    "                \n",
    "                with open(train_eval_log_file, 'a', newline='') as f:\n",
    "                    writer = csv.writer(f)\n",
    "                    writer.writerow([\n",
    "                        kernel_size, hidden, n_layers, \n",
    "                        f\"{train_eval_r2:.6f}\", f\"{train_eval_rmse:.6f}\", f\"{train_eval_time:.2f}\"\n",
    "                    ])\n",
    "                \n",
    "                logger.info(f\"Full Train Set Eval: R2={train_eval_r2:.6f}, RMSE={train_eval_rmse:.6f}, Time={train_eval_time:.2f}s\")\n",
    "\n",
    "                # --- Test Set Evaluation ---\n",
    "                def run_testing(test_files: List[Tuple[str, str]], test_dir: str, resolution: str):\n",
    "                    for drv_file, lbl_file in test_files:\n",
    "                        event_name = drv_file.replace('_X.h5', '')\n",
    "                        drv_path = os.path.join(test_dir, drv_file)\n",
    "                        lbl_path = os.path.join(test_dir, lbl_file)\n",
    "                        \n",
    "                        logger.info(f\"Memory state before testing event {event_name}:\")\n",
    "                        print_memory_usage()\n",
    "\n",
    "                        if resolution == \"30m\":\n",
    "                            logger.info(f\"Using Chunked Loader for 30m data (Chunk size: {args.hf_chunk_size})\")\n",
    "                            test_ds = Flood3DChunkedTestDataset(\n",
    "                                driver_path=drv_path, label_path=lbl_path,\n",
    "                                driver_key='data', label_key='data',\n",
    "                                chunk_size=args.hf_chunk_size\n",
    "                            )\n",
    "                            test_batch_size = 2\n",
    "                        else:\n",
    "                            logger.info(\"Using Full-Load Loader for 100m data\")\n",
    "                            test_ds = Flood3DTestDataset(\n",
    "                                driver_path=drv_path, label_path=lbl_path,\n",
    "                                driver_key='data', label_key='data'\n",
    "                            )\n",
    "                            test_batch_size = 4\n",
    "                            \n",
    "                        test_loader = DataLoader(\n",
    "                            test_ds, \n",
    "                            batch_size=test_batch_size, \n",
    "                            shuffle=False,\n",
    "                            pin_memory=True,\n",
    "                            num_workers=0\n",
    "                        )\n",
    "\n",
    "                        r2, rmse, test_time = predict_and_evaluate(model, test_loader, device)\n",
    "\n",
    "                        with open(test_log_file, 'a', newline='') as f:\n",
    "                            writer = csv.writer(f)\n",
    "                            writer.writerow([\n",
    "                                kernel_size, hidden, n_layers, \n",
    "                                resolution, event_name, f\"{r2:.4f}\", f\"{rmse:.4f}\", f\"{test_time:.2f}\"\n",
    "                            ])\n",
    "                        \n",
    "                        logger.info(f\"Event: {event_name}, Res: {resolution}, \"\n",
    "                                   f\"R2={r2:.4f}, RMSE={rmse:.4f}, Time={test_time:.2f}s\")\n",
    "                        \n",
    "                        del test_ds, test_loader\n",
    "                        clean_memory()\n",
    "\n",
    "                logger.info(\"Testing on 100m dataset...\")\n",
    "                run_testing(test_100m_files, args.test_100m_dir, \"100m\")\n",
    "\n",
    "                logger.info(\"Testing on 30m (ZS-SR) dataset...\")\n",
    "                run_testing(test_30m_files, args.test_30m_dir, \"30m\")\n",
    "\n",
    "                del model\n",
    "                clean_memory()\n",
    "                logger.info(f\"Memory state after experiment {exp_id}:\")\n",
    "                print_memory_usage()\n",
    "\n",
    "    logger.info(f\"\\nAll ConvLSTM experiments complete!\")\n",
    "    logger.info(f\"Test results saved to: {test_log_file}\")\n",
    "    logger.info(f\"Training set evaluation results saved to: {train_eval_log_file}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 1. Parse command-line arguments\n",
    "    args = get_args()\n",
    "    \n",
    "    # 2. Log the configuration\n",
    "    logger.info(\"Starting ConvLSTM run with configuration:\")\n",
    "    logger.info(\"=\" * 30)\n",
    "    for k, v in vars(args).items():\n",
    "        logger.info(f\"{k}: {v}\")\n",
    "    logger.info(\"=\" * 30)\n",
    "    \n",
    "    # 3. Run the main function\n",
    "    main(args)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flood_env_py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
